{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NPG, TRPO, ACER, PPO, ACKTR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from scipy.stats import uniform, argus, alpha, beta, rv_continuous, rv_discrete\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from gym import Wrapper\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "from itertools import count\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def c_softmax(x, sf=1, mag=2, shift=1):\n",
    "    return 1/(1 + np.exp(-x * sf)) * mag - shift\n",
    "def p_tanh(x, power=3, expl=0.001, mag=1, shift=0):\n",
    "    return np.tanh(np.power(x, power) * expl) * mag - shift\n",
    "def t_power(x, power=2, expl=0.5, mag=2, shift=1):\n",
    "    return np.tanh(np.sign(x) * np.power(x, power) * expl) * mag - shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseAgent():\n",
    "    def _set_seed(self, seed, env):\n",
    "        env.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "\n",
    "    def _extract_x(self, X):\n",
    "        seed,  environments = X[0]\n",
    "        environments = {\n",
    "            env.env.unwrapped.__class__.__name__:{'env':env} for env in environments\n",
    "        }\n",
    "        return seed, environments\n",
    "\n",
    "    def fit(self, X):\n",
    "        seed, environments = self._extract_x(X)\n",
    "        self.results = {}\n",
    "        for env_name, env_data in environments.items():\n",
    "            env = env_data['env'].env\n",
    "            gamma = env_data['env'].gamma\n",
    "            max_episodes = env_data['env'].max_episodes\n",
    "            goal_mean_reward = env_data['env'].goal_mean_reward\n",
    "            self._set_seed(seed, env)\n",
    "            print('Training on {} environment with seed {} and params {}'.format(env_name, seed, self.params))\n",
    "            self.results[env_name] = self.train(env, gamma, max_episodes, goal_mean_reward)\n",
    "        return self.results\n",
    "\n",
    "    def score(self, X):\n",
    "        seed, environments = self._extract_x(X)\n",
    "        total_score = 0\n",
    "        for env_name, env_data in environments.items():\n",
    "            env = env_data['env'].env\n",
    "            self._set_seed(seed, env)\n",
    "            \n",
    "            policy = self.results[env_name]['policy']\n",
    "            e_mean_reward = self.evaluate(env, policy)\n",
    "            t_episodes = self.results[env_name]['training_episodes']\n",
    "            t_episodes_weight = env_data['env'].training_episodes_weight\n",
    "            t_mean_reward = self.results[env_name]['training_mean_reward']\n",
    "            t_mean_reward_weight = env_data['env'].training_mean_reward_weight\n",
    "            e_mean_reward_weight = env_data['env'].evaluation_mean_reward_weight\n",
    "            goal_mean_reward = env_data['env'].goal_mean_reward\n",
    "\n",
    "            e_mean_reward_score = c_softmax(e_mean_reward / goal_mean_reward - 1, 50)\n",
    "            w_e_mean_reward_score = e_mean_reward_score * e_mean_reward_weight\n",
    "            \n",
    "            t_mean_reward_bonus = c_softmax(t_mean_reward / goal_mean_reward - 1, 50)\n",
    "            w_t_mean_reward_bonus = t_mean_reward_bonus * t_mean_reward_weight\n",
    "            \n",
    "            t_episodes_bonus = t_power(env_data['env'].max_episodes/t_episodes - 1)\n",
    "            w_t_episodes_bonus = t_episodes_bonus * t_episodes_weight\n",
    "            \n",
    "            score = w_e_mean_reward_score + w_t_episodes_bonus + w_t_mean_reward_bonus\n",
    "\n",
    "            print(\"Score in the {} environment with seed {}:\"\n",
    "                  \"\\nAgent = {}\"\n",
    "                  \"\\nScore = {}. Breakdown:\"\n",
    "                  \"\\n\\tEvaluation mean reward = {}, normalized = {}, weighted = {}\"\n",
    "                  \"\\n\\tTraining mean reward = {}, normalized = {}, weighted = {}\"\n",
    "                  \"\\n\\tTraining episodes = {}, normalized = {}, weighted = {}\"\n",
    "                  \"\".format(env_name, seed, \n",
    "                            self,\n",
    "                            score,\n",
    "                            e_mean_reward, e_mean_reward_score, w_e_mean_reward_score,\n",
    "                            t_mean_reward, t_mean_reward_bonus, w_t_mean_reward_bonus,\n",
    "                            t_episodes, t_episodes_bonus, w_t_episodes_bonus))\n",
    "            total_score += score\n",
    "\n",
    "        print('Total score across all environments for seed {} = {}'.format(seed, total_score))\n",
    "        print('---------------------------------------------\\n')\n",
    "        return total_score\n",
    "    \n",
    "    def demo(self, environment, results):\n",
    "        self.evaluate(env=environment.env, episodes=1, \n",
    "                      policy=results[environment.get_environment_name()]['policy'], \n",
    "                      render=True)\n",
    "        \n",
    "    def get_params(self, deep=False):\n",
    "        return self.params\n",
    "\n",
    "    def set_params(self, **params):\n",
    "        self.params = {\n",
    "            k:v for k, v in params.items()\n",
    "        }\n",
    "        for k, v in self.params.items():\n",
    "            setattr(self, k, v)\n",
    "        return self\n",
    "\n",
    "    def __repr__(self):\n",
    "        class_name = self.__class__.__name__\n",
    "        params_str = ', '.join([str(k) + '=' + str(v) for k, v in self.params.items()])\n",
    "        return '%s(%s)' % (class_name, params_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Qlearning(BaseAgent):\n",
    "    def __init__(self):\n",
    "        self.params = {}\n",
    "        self.results = {}\n",
    "        \n",
    "    def train(self, env, gamma, max_episodes, goal_mean_reward):\n",
    "        nS, nA = env.observation_space.n, env.action_space.n\n",
    "        Q = np.zeros((nS, nA))\n",
    "\n",
    "        rewards = []\n",
    "        with tqdm(total=max_episodes) as pbar:\n",
    "            for e in range(max_episodes):\n",
    "                state, done = env.reset(), False\n",
    "                self.behavioral_strategy.reset()\n",
    "                rewards.append(0)\n",
    "                while not done:\n",
    "                    action = self.behavioral_strategy.select_action(Q[state])\n",
    "                    new_state, reward, done, _ = env.step(action)\n",
    "                    rewards[-1] += reward\n",
    "                    target = reward + (not done) * gamma * Q[new_state].max()\n",
    "                    error = target - Q[state][action]\n",
    "                    Q[state][action] += self.alpha() * error\n",
    "                    state = new_state\n",
    "\n",
    "                V = np.max(Q, axis=1)\n",
    "                policy = {s:a for s, a in enumerate(np.argmax(Q, axis=1))}\n",
    "                if e % (max_episodes/100) == 0:\n",
    "                    training_mean_reward = self.evaluate(env, policy)\n",
    "                    if training_mean_reward >= goal_mean_reward:\n",
    "                        pbar.update(pbar.total - e)\n",
    "                        break\n",
    "                pbar.update(1)\n",
    "        results = {\n",
    "            'Q': Q,\n",
    "            'V': V,\n",
    "            'policy': policy,\n",
    "            'training_episodes': e+1,\n",
    "            'training_mean_reward': training_mean_reward,\n",
    "        }\n",
    "        return results\n",
    "\n",
    "    def evaluate(self, env, policy, episodes=100, render=False):\n",
    "        rewards = []\n",
    "        for e in range(episodes):\n",
    "            state, is_terminal = env.reset(), False\n",
    "            rewards.append(0)\n",
    "            for t in count(start=1):\n",
    "                if render: env.render()\n",
    "                action = policy[state]\n",
    "                state, reward, is_terminal, _ = env.step(action)\n",
    "                rewards[-1] += reward\n",
    "                if is_terminal:\n",
    "                    break\n",
    "\n",
    "        if render: env.render()\n",
    "        env.close()\n",
    "        return np.mean(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseSchedule():\n",
    "    def __init__(self, *args, **kwds):\n",
    "        self.params = kwds\n",
    "        for k, v in self.params.items():\n",
    "            setattr(self, k, v)\n",
    "        self.reset()\n",
    "    def __call__(self):\n",
    "        raise NotImplemented\n",
    "    def reset(self):\n",
    "        setattr(self, '_t', 0)\n",
    "    @property\n",
    "    def tick(self):\n",
    "        curr_t = self._t\n",
    "        self._t += 1\n",
    "        return curr_t\n",
    "    def __repr__(self):\n",
    "        class_name = self.__class__.__name__\n",
    "        self.params['value'] = self.value\n",
    "        params_str = ', '.join(['{}={}'.format(k, round(v, 3)) for k, v in self.params.items()])\n",
    "        return \"{}({})\".format(class_name, params_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConstantSchedule(BaseSchedule):\n",
    "    def __call__(self):\n",
    "        self.tick\n",
    "        return self.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearlyDecayingSchedule(BaseSchedule):\n",
    "    def __call__(self):\n",
    "        self.value = max(self.min_value, self.initial_value - (1 - self.decay_rate) * self.tick)\n",
    "        return self.value\n",
    "    def reset(self):\n",
    "        super(LinearlyDecayingSchedule, self).reset()\n",
    "        self.value = self.initial_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExponentiallyDecayingSchedule(BaseSchedule):\n",
    "    def __call__(self):\n",
    "        self.value = max(self.min_value, self.initial_value * np.exp((self.decay_rate - 1) * self.tick))\n",
    "        return self.value\n",
    "    def reset(self):\n",
    "        super(ExponentiallyDecayingSchedule, self).reset()\n",
    "        self.value = self.initial_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.45180440585549864 ConstantSchedule(value=0.452)\n",
      "1 0.45180440585549864 ConstantSchedule(value=0.452)\n",
      "2 0.45180440585549864 ConstantSchedule(value=0.452)\n",
      "0 ConstantSchedule(value=0.452)\n",
      "ConstantSchedule(value=0.452)\n",
      "0.45180440585549864 0.45180440585549864 0.45180440585549864\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "s = ConstantSchedule(value=uniform().rvs())\n",
    "for i in range(np.random.randint(10)):\n",
    "    print(s._t, s(), s)\n",
    "s.reset()\n",
    "print(s._t, s)\n",
    "x, y = [], []\n",
    "for i in range(1000):\n",
    "    x.append(i)\n",
    "    y.append(s())\n",
    "print(s)\n",
    "print(np.min(y), np.mean(y), np.max(y))\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.0 LinearlyDecayingSchedule(initial_value=1.0, min_value=0.01, decay_rate=0.99, value=1.0)\n",
      "0 LinearlyDecayingSchedule(initial_value=1.0, min_value=0.01, decay_rate=0.99, value=1.0)\n",
      "LinearlyDecayingSchedule(initial_value=1.0, min_value=0.01, decay_rate=0.99, value=0.01)\n",
      "0.01 0.05949999999999995 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "s = LinearlyDecayingSchedule(initial_value=1.0, min_value=0.01, decay_rate=0.99)\n",
    "for i in range(np.random.randint(10)):\n",
    "    print(s._t, s(), s)\n",
    "s.reset()\n",
    "print(s._t, s)\n",
    "x, y = [], []\n",
    "for i in range(1000):\n",
    "    x.append(i)\n",
    "    y.append(s())\n",
    "print(s)\n",
    "print(np.min(y), np.mean(y), np.max(y))\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.0 ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.01, decay_rate=0.99, value=1.0)\n",
      "1 0.990049833749168 ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.01, decay_rate=0.99, value=0.99)\n",
      "2 0.9801986733067553 ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.01, decay_rate=0.99, value=0.98)\n",
      "3 0.9704455335485082 ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.01, decay_rate=0.99, value=0.97)\n",
      "4 0.9607894391523232 ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.01, decay_rate=0.99, value=0.961)\n",
      "0 ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.01, decay_rate=0.99, value=1.0)\n",
      "ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.01, decay_rate=0.99, value=0.01)\n",
      "0.01 0.10489066729883752 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "s = ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.01, decay_rate=0.99)\n",
    "for i in range(np.random.randint(10)):\n",
    "    print(s._t, s(), s)\n",
    "s.reset()\n",
    "print(s._t, s)\n",
    "x, y = [], []\n",
    "for i in range(1000):\n",
    "    x.append(i)\n",
    "    y.append(s())\n",
    "print(s)\n",
    "print(np.min(y), np.mean(y), np.max(y))\n",
    "plt.plot(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpsilonGreedyPolicy():\n",
    "    def __init__(self, epsilon_schedule):\n",
    "        self.epsilon_schedule = epsilon_schedule\n",
    "        self.epsilon = self.epsilon_schedule()\n",
    "    def reset(self):\n",
    "        self.epsilon_schedule.reset()\n",
    "    def select_action(self, Qs):\n",
    "        action = np.argmax(Qs) if np.random.random() > self.epsilon else np.random.randint(len(Qs))\n",
    "        self.epsilon = self.epsilon_schedule()\n",
    "        return action\n",
    "    def __repr__(self):\n",
    "        class_name = self.__class__.__name__\n",
    "        return \"{}(epsilon={}, {})\".format(class_name, self.epsilon, self.epsilon_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EpsilonGreedyPolicy(epsilon=0.9, ExponentiallyDecayingSchedule(initial_value=0.9, min_value=0.1, decay_rate=0.398, value=0.9))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = EpsilonGreedyPolicy(\n",
    "    epsilon_schedule=ExponentiallyDecayingSchedule(\n",
    "        initial_value=0.9, \n",
    "        min_value=0.1, \n",
    "        decay_rate=uniform().rvs()))\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7451733400516704 0.9579710233314589 0.999679129131949\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lot = [argus(6).rvs() for _ in range(1000)]\n",
    "print(np.min(lot), np.mean(lot), np.max(lot))\n",
    "plt.hist(lot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001685830822697465 0.06486158574486038 0.4748855720195916\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class argus_complement(rv_continuous):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.argus = argus(*args, **kwargs)\n",
    "    def rvs(self, *args, **kwargs):\n",
    "        argus_value = self.argus.rvs(*args, **kwargs) \n",
    "        return min(max(0.0, 1 - argus_value), 1.0)\n",
    "lot = [argus_complement(5).rvs() for _ in range(1000)]\n",
    "print(np.min(lot), np.mean(lot), np.max(lot))\n",
    "plt.hist(lot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.044368217298718836 0.4969017113835828 0.9324051465157296\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lot = [beta(5, 5).rvs() for _ in range(1000)]\n",
    "print(np.min(lot), np.mean(lot), np.max(lot))\n",
    "plt.hist(lot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7849796848612132 0.968031297000859 0.9999958029617093\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class beta_complement(rv_continuous):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.beta = beta(*args, **kwargs)\n",
    "    def rvs(self, *args, **kwargs):\n",
    "        beta_value = self.beta.rvs(*args, **kwargs) \n",
    "        return min(max(0, 1 - beta_value), 1.0)\n",
    "lot = [beta_complement(1, 30).rvs() for _ in range(1000)]\n",
    "print(np.min(lot), np.mean(lot), np.max(lot))\n",
    "plt.hist(lot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def c_softmax(x, sf=1, mag=2, shift=1):\n",
    "    return 1/(1 + np.exp(-x * sf)) * mag - shift\n",
    "x = np.arange(-2, 2, 0.01)\n",
    "lot = [c_softmax(i, 1, 2, 1) for i in x]\n",
    "plt.plot(x, lot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def p_tanh(x, power=3, expl=0.001, mag=1, shift=0):\n",
    "    return np.tanh(np.power(x, power) * expl) * mag - shift\n",
    "x = np.arange(-15, 15, 0.01)\n",
    "lot = [p_tanh(i) for i in x]\n",
    "plt.plot(x, lot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def t_power(x, power=2, expl=0.5, mag=2, shift=1):\n",
    "    return np.tanh(np.sign(x) * np.power(x, power) * expl) * mag - shift\n",
    "x = np.arange(0, 5, 0.01)\n",
    "lot = [t_power(i, power=2, expl=0.5) for i in x]\n",
    "plt.plot(x, lot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingConfiguration:\n",
    "    def __init__(self, seeds, environments):\n",
    "        self.seeds = seeds\n",
    "        self.environments = environments\n",
    "    def data(self):\n",
    "        return [(seed, self.environments) for seed in self.seeds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingEnvironment:\n",
    "    def __init__(self, \n",
    "                 env, \n",
    "                 gamma,\n",
    "                 max_episodes, \n",
    "                 goal_mean_reward,\n",
    "                 training_mean_reward_weight,\n",
    "                 training_episodes_weight,\n",
    "                 evaluation_mean_reward_weight):\n",
    "        self.env = env\n",
    "        self.gamma = gamma\n",
    "        self.max_episodes = max_episodes\n",
    "        self.goal_mean_reward = goal_mean_reward\n",
    "        self.training_mean_reward_weight = training_mean_reward_weight\n",
    "        self.training_episodes_weight = training_episodes_weight\n",
    "        self.evaluation_mean_reward_weight = evaluation_mean_reward_weight\n",
    "    def get_environment_name(self):\n",
    "        return self.env.unwrapped.__class__.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds = (\n",
    "    12,\n",
    "    34,\n",
    "    56,\n",
    "    78,\n",
    "    90,\n",
    ")\n",
    "\n",
    "environments = (\n",
    "    TrainingEnvironment(\n",
    "        env=gym.make('FrozenLake-v0'), \n",
    "        gamma=0.99,\n",
    "        max_episodes=5000,\n",
    "        goal_mean_reward=0.70,\n",
    "        training_mean_reward_weight=0.1,\n",
    "        training_episodes_weight=0.2,\n",
    "        evaluation_mean_reward_weight=0.7,\n",
    "    ),\n",
    "    #TrainingEnvironment(\n",
    "    #    env=gym.make('Taxi-v2'), \n",
    "    #    max_episodes=100000,\n",
    "    #    goal_mean_reward=800,\n",
    "    #    training_mean_reward_weight=0.03,\n",
    "    #    training_episodes_weight=0.07,\n",
    "    #    evaluation_mean_reward_weight=0.9,\n",
    "    #),\n",
    ")\n",
    "\n",
    "training_configuration = TrainingConfiguration(seeds=seeds, environments=environments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParamGrid():\n",
    "    def __init__(self):\n",
    "        self.grid = {}\n",
    "    def add(self, param, func, times=5):\n",
    "        if param not in self.grid:\n",
    "            self.grid[param] = []\n",
    "        self.grid[param] += [func() for _ in range(times)]\n",
    "    def data(self):\n",
    "        return self.grid\n",
    "    def __len__(self):\n",
    "        count = 0\n",
    "        for k, v in self.grid.items():\n",
    "            count += len(v)\n",
    "        return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': [ConstantSchedule(value=0.603),\n",
       "  ConstantSchedule(value=0.723),\n",
       "  ConstantSchedule(value=0.744),\n",
       "  ConstantSchedule(value=0.341),\n",
       "  ConstantSchedule(value=0.393),\n",
       "  LinearlyDecayingSchedule(initial_value=1.0, min_value=0.098, decay_rate=1.0, value=1.0),\n",
       "  LinearlyDecayingSchedule(initial_value=1.0, min_value=0.168, decay_rate=0.99, value=1.0),\n",
       "  LinearlyDecayingSchedule(initial_value=1.0, min_value=0.137, decay_rate=0.998, value=1.0),\n",
       "  LinearlyDecayingSchedule(initial_value=1.0, min_value=0.071, decay_rate=0.958, value=1.0),\n",
       "  LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=1.0),\n",
       "  ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.06, decay_rate=0.994, value=1.0),\n",
       "  ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.073, decay_rate=0.964, value=1.0),\n",
       "  ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.111, decay_rate=0.998, value=1.0),\n",
       "  ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.09, decay_rate=0.996, value=1.0),\n",
       "  ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=1.0)],\n",
       " 'behavioral_strategy': [EpsilonGreedyPolicy(epsilon=0.09891688511742908, ConstantSchedule(value=0.099)),\n",
       "  EpsilonGreedyPolicy(epsilon=0.0620865541722682, ConstantSchedule(value=0.062)),\n",
       "  EpsilonGreedyPolicy(epsilon=0.11536442599539684, ConstantSchedule(value=0.115)),\n",
       "  EpsilonGreedyPolicy(epsilon=0.11386286623716069, ConstantSchedule(value=0.114)),\n",
       "  EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)),\n",
       "  EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=1.0)),\n",
       "  EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.009, decay_rate=0.988, value=1.0)),\n",
       "  EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.007, decay_rate=0.998, value=1.0)),\n",
       "  EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.028, decay_rate=0.993, value=1.0)),\n",
       "  EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.98, value=1.0)),\n",
       "  EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.01, decay_rate=0.999, value=1.0)),\n",
       "  EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.996, value=1.0)),\n",
       "  EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.023, decay_rate=0.993, value=1.0)),\n",
       "  EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=1.0)),\n",
       "  EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.999, value=1.0))]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = ParamGrid()\n",
    "grid.add(\n",
    "    'alpha', \n",
    "    lambda: ConstantSchedule(\n",
    "        value=beta(5, 5).rvs()\n",
    "    )\n",
    ")\n",
    "grid.add(\n",
    "    'alpha', \n",
    "    lambda: LinearlyDecayingSchedule(\n",
    "        initial_value=1.0, \n",
    "        min_value=beta(10, 80).rvs(), \n",
    "        decay_rate=beta(50, 0.6).rvs()\n",
    "    )\n",
    ")\n",
    "grid.add(\n",
    "    'alpha', \n",
    "    lambda: ExponentiallyDecayingSchedule(\n",
    "        initial_value=1.0, \n",
    "        min_value=beta(10, 80).rvs(), \n",
    "        decay_rate=beta(50, 0.6).rvs()\n",
    "    )\n",
    ")\n",
    "grid.add(\n",
    "    'behavioral_strategy', \n",
    "    lambda: EpsilonGreedyPolicy(\n",
    "        epsilon_schedule=ConstantSchedule(\n",
    "            value=beta(5, 50).rvs()\n",
    "        )\n",
    "    )\n",
    ")\n",
    "grid.add(\n",
    "    'behavioral_strategy', \n",
    "    lambda: EpsilonGreedyPolicy(\n",
    "        epsilon_schedule=LinearlyDecayingSchedule(\n",
    "            initial_value=1.0, \n",
    "            min_value=beta(1, 100).rvs(),\n",
    "            decay_rate=beta(50, 0.6).rvs()\n",
    "        )\n",
    "    )\n",
    ")\n",
    "grid.add(\n",
    "    'behavioral_strategy', \n",
    "    lambda: EpsilonGreedyPolicy(\n",
    "        epsilon_schedule=ExponentiallyDecayingSchedule(\n",
    "            initial_value=1.0, \n",
    "            min_value=beta(1, 100).rvs(),\n",
    "            decay_rate=beta(50, 0.6).rvs()\n",
    "        )\n",
    "    )\n",
    ")\n",
    "grid.data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneToOneCV:\n",
    "    def get_n_splits(self, X=None, y=None, groups=None):\n",
    "        return len(X)\n",
    "    def split(self, X, y=None, groups=None):\n",
    "        for i in range(len(X)):\n",
    "            yield [np.array([i]), np.array([i])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on FrozenLakeEnv environment with seed 34 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.009, decay_rate=0.988, value=1.0)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.168, decay_rate=0.99, value=1.0)}\n",
      "Training on FrozenLakeEnv environment with seed 12 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.009, decay_rate=0.988, value=1.0)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.168, decay_rate=0.99, value=1.0)}\n",
      "Training on FrozenLakeEnv environment with seed 78 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.009, decay_rate=0.988, value=1.0)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.168, decay_rate=0.99, value=1.0)}\n",
      "Training on FrozenLakeEnv environment with seed 56 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.009, decay_rate=0.988, value=1.0)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.168, decay_rate=0.99, value=1.0)}\n",
      "Training on FrozenLakeEnv environment with seed 90 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.009, decay_rate=0.988, value=1.0)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.168, decay_rate=0.99, value=1.0)}\n",
      "Training on FrozenLakeEnv environment with seed 12 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=1.0)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.071, decay_rate=0.958, value=1.0)}\n",
      "Training on FrozenLakeEnv environment with seed 34 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=1.0)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.071, decay_rate=0.958, value=1.0)}\n",
      "Training on FrozenLakeEnv environment with seed 56 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=1.0)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.071, decay_rate=0.958, value=1.0)}\n",
      "Training on FrozenLakeEnv environment with seed 56 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.11536442599539684, ConstantSchedule(value=0.115)), 'alpha': ConstantSchedule(value=0.723)}\n",
      "Training on FrozenLakeEnv environment with seed 90 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.11536442599539684, ConstantSchedule(value=0.115)), 'alpha': ConstantSchedule(value=0.723)}\n",
      "Training on FrozenLakeEnv environment with seed 34 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.11386286623716069, ConstantSchedule(value=0.114)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=1.0)}\n",
      "Training on FrozenLakeEnv environment with seed 12 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.11386286623716069, ConstantSchedule(value=0.114)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=1.0)}\n",
      "Training on FrozenLakeEnv environment with seed 78 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.11536442599539684, ConstantSchedule(value=0.115)), 'alpha': ConstantSchedule(value=0.723)}\n",
      "Training on FrozenLakeEnv environment with seed 56 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.11386286623716069, ConstantSchedule(value=0.114)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=1.0)}\n",
      "Training on FrozenLakeEnv environment with seed 78 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.11386286623716069, ConstantSchedule(value=0.114)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=1.0)}\n",
      "Training on FrozenLakeEnv environment with seed 90 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.11386286623716069, ConstantSchedule(value=0.114)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=1.0)}\n",
      "Training on FrozenLakeEnv environment with seed 12 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.0620865541722682, ConstantSchedule(value=0.062)), 'alpha': ConstantSchedule(value=0.341)}\n",
      "Training on FrozenLakeEnv environment with seed 56 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.0620865541722682, ConstantSchedule(value=0.062)), 'alpha': ConstantSchedule(value=0.341)}\n",
      "Training on FrozenLakeEnv environment with seed 78 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.0620865541722682, ConstantSchedule(value=0.062)), 'alpha': ConstantSchedule(value=0.341)}\n",
      "Training on FrozenLakeEnv environment with seed 34 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.0620865541722682, ConstantSchedule(value=0.062)), 'alpha': ConstantSchedule(value=0.341)}\n",
      "Training on FrozenLakeEnv environment with seed 90 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.0620865541722682, ConstantSchedule(value=0.062)), 'alpha': ConstantSchedule(value=0.341)}\n",
      "Training on FrozenLakeEnv environment with seed 12 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.11536442599539684, ConstantSchedule(value=0.115)), 'alpha': ConstantSchedule(value=0.723)}\n",
      "Training on FrozenLakeEnv environment with seed 12 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.09, decay_rate=0.996, value=1.0)}\n",
      "Training on FrozenLakeEnv environment with seed 56 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.09, decay_rate=0.996, value=1.0)}\n",
      "Training on FrozenLakeEnv environment with seed 34 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.09, decay_rate=0.996, value=1.0)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4c2d8e6182042a38529ca41cfb3d5cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on FrozenLakeEnv environment with seed 90 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.09, decay_rate=0.996, value=1.0)}\n",
      "Training on FrozenLakeEnv environment with seed 78 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.09, decay_rate=0.996, value=1.0)}\n",
      "Training on FrozenLakeEnv environment with seed 34 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.09891688511742908, ConstantSchedule(value=0.099)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=1.0)}\n",
      "Training on FrozenLakeEnv environment with seed 78 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=1.0)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.071, decay_rate=0.958, value=1.0)}\n",
      "Training on FrozenLakeEnv environment with seed 12 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.09891688511742908, ConstantSchedule(value=0.099)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=1.0)}\n",
      "Training on FrozenLakeEnv environment with seed 34 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.11536442599539684, ConstantSchedule(value=0.115)), 'alpha': ConstantSchedule(value=0.723)}\n",
      "Training on FrozenLakeEnv environment with seed 90 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=1.0)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.071, decay_rate=0.958, value=1.0)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19b2628c42aa4190a8ef30bbe14b9e31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4b96177a558472994b027782104d487",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddfce627fe5d41c39285beac588396cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d4b9dc555f542a6921180d04c025292",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2bfd007cb4540f1ad3fc7e6fa740f86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5b66858f4a6429c940213f145baa662",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ef6685c0e12414f8f75e09d87f04232",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbb31c7163534f64b7ca084be7c79f8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61dc9ba21c454221be7b1668cf5efcda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fd1e8271ff84c5e852fb42d2d9e6c2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73539e43025a4fdbb2f5769acab3da53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d08b99f428247a18c4543c7356876a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a473c067eb2142f48b6e23415fdab531",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a34619d5d55c40d793b08c6216251802",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c33ffe1ad2e045bf99ed4a304ed2742a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c16cafe70b6f4bdf8d5e7bba3cc04516",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6abbbc123c4b46cbbaa16f1e17f85cea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9036a4846e74f53a27488e42d975fb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96f845dab0664e20b2831a44f0b8bffd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54c683dff529401aad53a79fe728778f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82e58f7659304f418903e2775df54fb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aa0278c4f114595a355be54be2d11d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2828154d89a489ca3fd39e212a15061",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7281b0bbcc8f4c068a031f4ee288483c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db901bcf11a0461cb19a22992883c27a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5545095a4054121a6f9f3307b548fef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b181de43eea84dd0aea70e90e33c05d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5a83d2e8dea43fda200505524b30086",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08c20953d00b49c88005174132f2e8d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f243a5ac5a9c44279a78a49a93e4453a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c314cf5afd5441d9a1ea67c45179a6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score in the FrozenLakeEnv environment with seed 12:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9628540027476498, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.009, decay_rate=0.988, value=0.963)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.168, decay_rate=0.99, value=0.168))\n",
      "Score = -0.4657152780942059. Breakdown:\n",
      "\tEvaluation mean reward = 0.54, normalized = -0.9999782399563084, weighted = -0.6999847679694159\n",
      "\tTraining mean reward = 0.71, normalized = 0.3426949069654588, weighted = 0.03426949069654588\n",
      "\tTraining episodes = 901, normalized = 0.9999999958933206, weighted = 0.19999999917866412\n",
      "Total score across all environments for seed 12 = -0.4657152780942059\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 56 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.09891688511742908, ConstantSchedule(value=0.099)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=1.0)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c16dde30998b4f3483032acb3700e96d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 90:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.950472003663533, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.009, decay_rate=0.988, value=0.95)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.168, decay_rate=0.99, value=0.168))\n",
      "Score = 0.9939580773746546. Breakdown:\n",
      "\tEvaluation mean reward = 0.78, normalized = 0.9934246772281319, weighted = 0.6953972740596923\n",
      "\tTraining mean reward = 0.77, normalized = 0.9866142981514305, weighted = 0.09866142981514306\n",
      "\tTraining episodes = 1251, normalized = 0.9994968674990963, weighted = 0.19989937349981926\n",
      "Total score across all environments for seed 90 = 0.9939580773746546\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 78 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.09891688511742908, ConstantSchedule(value=0.099)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=1.0)}\n",
      "Score in the FrozenLakeEnv environment with seed 34:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9997594490893471, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=1.0)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.071, decay_rate=0.958, value=0.071))\n",
      "Score = 0.9110856890814126. Breakdown:\n",
      "\tEvaluation mean reward = 0.74, normalized = 0.8913734677347187, weighted = 0.623961427414303\n",
      "\tTraining mean reward = 0.74, normalized = 0.8913734677347187, weighted = 0.08913734677347188\n",
      "\tTraining episodes = 1451, normalized = 0.9899345744681884, weighted = 0.1979869148936377\n",
      "Total score across all environments for seed 34 = 0.9110856890814126\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 90 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.09891688511742908, ConstantSchedule(value=0.099)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=1.0)}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aff90919bc1443c8dbfa3bfc75db5fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score in the FrozenLakeEnv environment with seed 78:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9876180009158833, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.009, decay_rate=0.988, value=0.988)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.168, decay_rate=0.99, value=0.168))\n",
      "Score = -0.4622155317827092. Breakdown:\n",
      "\tEvaluation mean reward = 0.62, normalized = -0.993424677228132, weighted = -0.6953972740596923\n",
      "\tTraining mean reward = 0.71, normalized = 0.3426949069654588, weighted = 0.03426949069654588\n",
      "\tTraining episodes = 1401, normalized = 0.9945612579021861, weighted = 0.19891225158043724\n",
      "Total score across all environments for seed 78 = -0.4622155317827092\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 12 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.98, value=1.0)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=1.0)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6e62d3298784738884832d750d5b9da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score in the FrozenLakeEnv environment with seed 56:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9996391736340207, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=1.0)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.071, decay_rate=0.958, value=0.071))\n",
      "Score = 0.8057841581332867. Breakdown:\n",
      "\tEvaluation mean reward = 0.74, normalized = 0.8913734677347187, weighted = 0.623961427414303\n",
      "\tTraining mean reward = 0.7, normalized = 0.0, weighted = 0.0\n",
      "\tTraining episodes = 1701, normalized = 0.9091136535949187, weighted = 0.18182273071898375\n",
      "Total score across all environments for seed 56 = 0.8057841581332867\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 34 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.98, value=1.0)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=1.0)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e44bc429364740ecbc590ee4a4ec85f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c7f6b71a02d482fb0dbda74ca607bfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score in the FrozenLakeEnv environment with seed 56:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.8142700137382488, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.009, decay_rate=0.988, value=0.814)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.168, decay_rate=0.99, value=0.168))\n",
      "Score = 0.8871530078838054. Breakdown:\n",
      "\tEvaluation mean reward = 0.77, normalized = 0.9866142981514305, weighted = 0.6906300087060013\n",
      "\tTraining mean reward = 0.7, normalized = 0.0, weighted = 0.0\n",
      "\tTraining episodes = 1501, normalized = 0.98261499588902, weighted = 0.19652299917780403\n",
      "Total score across all environments for seed 56 = 0.8871530078838054\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 56 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.98, value=1.0)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=1.0)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21ef205ca7184986b40fa23cbb5570c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 90:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9998797245446736, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=1.0)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.071, decay_rate=0.958, value=0.071))\n",
      "Score = -0.5170859994475904. Breakdown:\n",
      "\tEvaluation mean reward = 0.61, normalized = -0.9967756945029475, weighted = -0.6977429861520632\n",
      "\tTraining mean reward = 0.77, normalized = 0.9866142981514305, weighted = 0.09866142981514306\n",
      "\tTraining episodes = 2151, normalized = 0.40997778444664923, weighted = 0.08199555688932986\n",
      "Total score across all environments for seed 90 = -0.5170859994475904\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 78 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.98, value=1.0)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=1.0)}\n",
      "Score in the FrozenLakeEnv environment with seed 78:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.972295936209412, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=0.972)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.09, decay_rate=0.996, value=0.09))\n",
      "Score = -0.47740513238097687. Breakdown:\n",
      "\tEvaluation mean reward = 0.62, normalized = -0.993424677228132, weighted = -0.6953972740596923\n",
      "\tTraining mean reward = 0.75, normalized = 0.9453064264076343, weighted = 0.09453064264076344\n",
      "\tTraining episodes = 2001, normalized = 0.6173074951897601, weighted = 0.12346149903795203\n",
      "Total score across all environments for seed 78 = -0.47740513238097687\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 90 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.98, value=1.0)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=1.0)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d6590f5c8664af5b94804c5ff1ac2aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18da506c30e54ea6a699be353cf826d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 56:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9624131553491263, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=0.962)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.09, decay_rate=0.996, value=0.09))\n",
      "Score = 0.9356106243511527. Breakdown:\n",
      "\tEvaluation mean reward = 0.8, normalized = 0.9984202681165271, weighted = 0.6988941876815689\n",
      "\tTraining mean reward = 0.74, normalized = 0.8913734677347187, weighted = 0.08913734677347188\n",
      "\tTraining episodes = 1901, normalized = 0.7378954494805599, weighted = 0.147579089896112\n",
      "Total score across all environments for seed 56 = 0.9356106243511527\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 12 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.073, decay_rate=0.964, value=1.0)}\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 12:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9993986227233678, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=0.999)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.071, decay_rate=0.958, value=0.071))\n",
      "Score = -0.3294464035501151. Breakdown:\n",
      "\tEvaluation mean reward = 0.68, normalized = -0.613357260395381, weighted = -0.42935008227676663\n",
      "\tTraining mean reward = 0.74, normalized = 0.8913734677347187, weighted = 0.08913734677347188\n",
      "\tTraining episodes = 2401, normalized = 0.0538316597658981, weighted = 0.01076633195317962\n",
      "Total score across all environments for seed 12 = -0.3294464035501151\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 34 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.073, decay_rate=0.964, value=1.0)}\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 12:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9974491625889466, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=0.997)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.09, decay_rate=0.996, value=0.09))\n",
      "Score = 0.5822245511523796. Breakdown:\n",
      "\tEvaluation mean reward = 0.72, normalized = 0.6133572603953845, weighted = 0.42935008227676913\n",
      "\tTraining mean reward = 0.8, normalized = 0.9984202681165271, weighted = 0.09984202681165272\n",
      "\tTraining episodes = 2251, normalized = 0.26516221031978904, weighted = 0.05303244206395781\n",
      "Total score across all environments for seed 12 = 0.5822245511523796\n",
      "---------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33dc73d654cf40dd8b80951fbe8127a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on FrozenLakeEnv environment with seed 56 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.073, decay_rate=0.964, value=1.0)}\n",
      "Score in the FrozenLakeEnv environment with seed 34:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9133260064111828, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.009, decay_rate=0.988, value=0.913)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.168, decay_rate=0.99, value=0.168))\n",
      "Score = 0.8313093749539672. Breakdown:\n",
      "\tEvaluation mean reward = 0.76, normalized = 0.9728461661125116, weighted = 0.6809923162787581\n",
      "\tTraining mean reward = 0.76, normalized = 0.9728461661125116, weighted = 0.09728461661125117\n",
      "\tTraining episodes = 2251, normalized = 0.26516221031978904, weighted = 0.05303244206395781"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a66d93140e294f8f89873ba42e0e673d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total score across all environments for seed 34 = 0.8313093749539672\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 78 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.073, decay_rate=0.964, value=1.0)}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49e954dc9a1c447aa956ef462878f288",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score in the FrozenLakeEnv environment with seed 56:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.11386286623716069, ConstantSchedule(value=0.114)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=0.052))\n",
      "Score = 0.7897058130144037. Breakdown:\n",
      "\tEvaluation mean reward = 0.79, normalized = 0.9967756945029476, weighted = 0.6977429861520632\n",
      "\tTraining mean reward = 0.75, normalized = 0.9453064264076343, weighted = 0.09453064264076344\n",
      "\tTraining episodes = 2451, normalized = -0.01283907889211533, weighted = -0.0025678157784230662\n",
      "Total score across all environments for seed 56 = 0.7897058130144037\n",
      "---------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9d949560028483592e3ba733015c6de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on FrozenLakeEnv environment with seed 90 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.073, decay_rate=0.964, value=1.0)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c92cafae7a9a4638a3fa14d9fbb286da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score in the FrozenLakeEnv environment with seed 34:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9309825943595155, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=0.931)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.073, decay_rate=0.964, value=0.073))\n",
      "Score = 0.9130987741877749. Breakdown:\n",
      "\tEvaluation mean reward = 0.74, normalized = 0.8913734677347187, weighted = 0.623961427414303\n",
      "\tTraining mean reward = 0.74, normalized = 0.8913734677347187, weighted = 0.08913734677347188\n",
      "\tTraining episodes = 251, normalized = 1.0, weighted = 0.2\n",
      "Total score across all environments for seed 34 = 0.9130987741877749\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 12 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)), 'alpha': ConstantSchedule(value=0.723)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d94f58c73744c3d89a622cb7a822180",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score in the FrozenLakeEnv environment with seed 56:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9185558675613521, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.98, value=0.919)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=0.052))\n",
      "Score = -0.33492470714101163. Breakdown:\n",
      "\tEvaluation mean reward = 0.66, normalized = -0.8913734677347183, weighted = -0.6239614274143027\n",
      "\tTraining mean reward = 0.74, normalized = 0.8913734677347187, weighted = 0.08913734677347188\n",
      "\tTraining episodes = 1251, normalized = 0.9994968674990963, weighted = 0.19989937349981926\n",
      "Total score across all environments for seed 56 = -0.33492470714101163\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 34 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)), 'alpha': ConstantSchedule(value=0.723)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "257354b17071495480218abe2a647eb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score in the FrozenLakeEnv environment with seed 90:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9974491625889466, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=0.997)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.09, decay_rate=0.996, value=0.09))\n",
      "Score = -0.7783863334298268. Breakdown:\n",
      "\tEvaluation mean reward = 0.55, normalized = -0.9999555506739739, weighted = -0.6999688854717817\n",
      "\tTraining mean reward = 0.71, normalized = 0.3426949069654588, weighted = 0.03426949069654588\n",
      "\tTraining episodes = 3001, normalized = -0.5634346932729546, weighted = -0.11268693865459092\n",
      "Total score across all environments for seed 90 = -0.7783863334298268\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 56 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)), 'alpha': ConstantSchedule(value=0.723)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b61af858f3849e79fd7917259534cbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score in the FrozenLakeEnv environment with seed 34:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9389169006710141, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.98, value=0.939)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=0.052))\n",
      "Score = 0.8857766829397844. Breakdown:\n",
      "\tEvaluation mean reward = 0.74, normalized = 0.8913734677347187, weighted = 0.623961427414303\n",
      "\tTraining mean reward = 0.75, normalized = 0.9453064264076343, weighted = 0.09453064264076344\n",
      "\tTraining episodes = 1801, normalized = 0.8364230644235897, weighted = 0.16728461288471796\n",
      "Total score across all environments for seed 34 = 0.8857766829397844\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 78 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)), 'alpha': ConstantSchedule(value=0.723)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d83fccf5754749fa85e7e4e73649ed77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 12:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.11386286623716069, ConstantSchedule(value=0.114)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=0.052))\n",
      "Score = -0.7250694842246463. Breakdown:\n",
      "\tEvaluation mean reward = 0.65, normalized = -0.9453064264076338, weighted = -0.6617144984853437\n",
      "\tTraining mean reward = 0.71, normalized = 0.3426949069654588, weighted = 0.03426949069654588\n",
      "\tTraining episodes = 2901, normalized = -0.4881223821792423, weighted = -0.09762447643584847\n",
      "Total score across all environments for seed 12 = -0.7250694842246463\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 90 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)), 'alpha': ConstantSchedule(value=0.723)}\n",
      "Score in the FrozenLakeEnv environment with seed 90:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.0620865541722682, ConstantSchedule(value=0.062)), alpha=ConstantSchedule(value=0.341))\n",
      "Score = -0.48753873785150315. Breakdown:\n",
      "\tEvaluation mean reward = 0.68, normalized = -0.613357260395381, weighted = -0.42935008227676663\n",
      "\tTraining mean reward = 0.74, normalized = 0.8913734677347187, weighted = 0.08913734677347188\n",
      "\tTraining episodes = 3301, normalized = -0.736630011741042, weighted = -0.14732600234820842\n",
      "Total score across all environments for seed 90 = -0.48753873785150315\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 12 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.007, decay_rate=0.998, value=1.0)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.098, decay_rate=1.0, value=1.0)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ee75eab337d452f99b0171ab63b9748",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d30ed8e67364443683c82a80a2183841",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 78:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.979638966890338, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.98, value=0.98)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=0.052))\n",
      "Score = 0.497776687747657. Breakdown:\n",
      "\tEvaluation mean reward = 0.71, normalized = 0.3426949069654588, weighted = 0.23988643487582115\n",
      "\tTraining mean reward = 0.8, normalized = 0.9984202681165271, weighted = 0.09984202681165272\n",
      "\tTraining episodes = 1851, normalized = 0.7902411303009154, weighted = 0.1580482260601831\n",
      "Total score across all environments for seed 78 = 0.497776687747657\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 34 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.007, decay_rate=0.998, value=1.0)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.098, decay_rate=1.0, value=1.0)}\n",
      "Score in the FrozenLakeEnv environment with seed 12:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9185558675613521, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.98, value=0.919)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=0.052))\n",
      "Score = 0.500991857670545. Breakdown:\n",
      "\tEvaluation mean reward = 0.72, normalized = 0.6133572603953845, weighted = 0.42935008227676913\n",
      "\tTraining mean reward = 0.78, normalized = 0.9934246772281319, weighted = 0.09934246772281319\n",
      "\tTraining episodes = 2551, normalized = -0.13850346164518668, weighted = -0.027700692329037338\n",
      "Total score across all environments for seed 12 = 0.500991857670545\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 56 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.007, decay_rate=0.998, value=1.0)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.098, decay_rate=1.0, value=1.0)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6734769d2fee4d0e841ae7178fb10e3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64a837bc5b6c49e987e430cf9f289b7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score in the FrozenLakeEnv environment with seed 78:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9995188981786942, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=1.0)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.071, decay_rate=0.958, value=0.071))\n",
      "Score = 0.46389490567386904. Breakdown:\n",
      "\tEvaluation mean reward = 0.73, normalized = 0.7899988299594711, weighted = 0.5529991809716297\n",
      "\tTraining mean reward = 0.81, normalized = 0.999226343498715, weighted = 0.0999226343498715\n",
      "\tTraining episodes = 4051, normalized = -0.9451345482381608, weighted = -0.18902690964763216\n",
      "Total score across all environments for seed 78 = 0.46389490567386904\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 78 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.007, decay_rate=0.998, value=1.0)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.098, decay_rate=1.0, value=1.0)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87f0a27e6ca047719ff8cc6473818118",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score in the FrozenLakeEnv environment with seed 56:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9232512448220334, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.007, decay_rate=0.998, value=0.923)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.098, decay_rate=1.0, value=0.098))\n",
      "Score = 0.9964044159672062. Breakdown:\n",
      "\tEvaluation mean reward = 0.79, normalized = 0.9967756945029476, weighted = 0.6977429861520632\n",
      "\tTraining mean reward = 0.77, normalized = 0.9866142981514305, weighted = 0.09866142981514306\n",
      "\tTraining episodes = 301, normalized = 1.0, weighted = 0.2\n",
      "Total score across all environments for seed 56 = 0.9964044159672062\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 90 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.007, decay_rate=0.998, value=1.0)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.098, decay_rate=1.0, value=1.0)}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07f1b9d392e545e98683cd14c25c7681",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score in the FrozenLakeEnv environment with seed 12:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9898356246362454, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=0.99)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.073, decay_rate=0.964, value=0.073))\n",
      "Score = -0.2726850300498239. Breakdown:\n",
      "\tEvaluation mean reward = 0.68, normalized = -0.613357260395381, weighted = -0.42935008227676663\n",
      "\tTraining mean reward = 0.74, normalized = 0.8913734677347187, weighted = 0.08913734677347188\n",
      "\tTraining episodes = 2201, normalized = 0.3376385272673543, weighted = 0.06752770545347087\n",
      "Total score across all environments for seed 12 = -0.2726850300498239\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 12 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.028, decay_rate=0.993, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.06, decay_rate=0.994, value=1.0)}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b613a5d5cd3b493081b2d6cefbc68f4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score in the FrozenLakeEnv environment with seed 78:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9949048319493907, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=0.995)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.073, decay_rate=0.964, value=0.073))\n",
      "Score = 0.4008818747610981. Breakdown:\n",
      "\tEvaluation mean reward = 0.71, normalized = 0.3426949069654588, weighted = 0.23988643487582115\n",
      "\tTraining mean reward = 0.73, normalized = 0.7899988299594711, weighted = 0.07899988299594712\n",
      "\tTraining episodes = 2151, normalized = 0.40997778444664923, weighted = 0.08199555688932986\n",
      "Total score across all environments for seed 78 = 0.4008818747610981\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 34 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.028, decay_rate=0.993, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.06, decay_rate=0.994, value=1.0)}\n",
      "Score in the FrozenLakeEnv environment with seed 56:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.11536442599539684, ConstantSchedule(value=0.115)), alpha=ConstantSchedule(value=0.723))\n",
      "Score = 0.6040203870158334. Breakdown:\n",
      "\tEvaluation mean reward = 0.78, normalized = 0.9934246772281319, weighted = 0.6953972740596923\n",
      "\tTraining mean reward = 0.75, normalized = 0.9453064264076343, weighted = 0.09453064264076344\n",
      "\tTraining episodes = 3951, normalized = -0.9295376484231119, weighted = -0.1859075296846224\n",
      "Total score across all environments for seed 56 = 0.6040203870158334\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 56 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.028, decay_rate=0.993, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.06, decay_rate=0.994, value=1.0)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b3cc35937084f158749b7e0c4a68da2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee80a3fd737a431f8f1607f54a49db88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 90:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.8574727682323662, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.98, value=0.857)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=0.052))\n",
      "Score = -0.6318620984448858. Breakdown:\n",
      "\tEvaluation mean reward = 0.63, normalized = -0.9866142981514303, weighted = -0.6906300087060012\n",
      "\tTraining mean reward = 0.72, normalized = 0.6133572603953845, weighted = 0.061335726039538456\n",
      "\tTraining episodes = 2451, normalized = -0.01283907889211533, weighted = -0.0025678157784230662\n",
      "Total score across all environments for seed 90 = -0.6318620984448858\n",
      "---------------------------------------------\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 34:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9673419250195006, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=0.967)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.09, decay_rate=0.996, value=0.09))\n",
      "Score = -0.8572648745483469. Breakdown:\n",
      "\tEvaluation mean reward = 0.65, normalized = -0.9453064264076338, weighted = -0.6617144984853437\n",
      "\tTraining mean reward = 0.7, normalized = 0.0, weighted = 0.0\n",
      "\tTraining episodes = 4351, normalized = -0.977751880315016, weighted = -0.1955503760630032Score in the FrozenLakeEnv environment with seed 12:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9976016014006885, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.007, decay_rate=0.998, value=0.998)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.098, decay_rate=1.0, value=0.098))\n",
      "Score = -0.4340615480581679. Breakdown:\n",
      "\tEvaluation mean reward = 0.62, normalized = -0.993424677228132, weighted = -0.6953972740596923\n",
      "\tTraining mean reward = 0.72, normalized = 0.6133572603953845, weighted = 0.061335726039538456\n",
      "\tTraining episodes = 851, normalized = 0.9999999998099298, weighted = 0.19999999996198597\n",
      "Training on FrozenLakeEnv environment with seed 78 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.028, decay_rate=0.993, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.06, decay_rate=0.994, value=1.0)}\n",
      "\n",
      "Total score across all environments for seed 34 = -0.8572648745483469\n",
      "Total score across all environments for seed 12 = -0.4340615480581679\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 90 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.028, decay_rate=0.993, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.06, decay_rate=0.994, value=1.0)}\n",
      "Training on FrozenLakeEnv environment with seed 12 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.028, decay_rate=0.993, value=1.0)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=1.0)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae64f7964a2a41fea5431278a10489ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c1d4a76e98144b79d9afee89f0a1e06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3724f90493de4feab137e6ce3e194dda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score in the FrozenLakeEnv environment with seed 34:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.11536442599539684, ConstantSchedule(value=0.115)), alpha=ConstantSchedule(value=0.723))\n",
      "Score = -0.9999999999999999. Breakdown:\n",
      "\tEvaluation mean reward = 0.0, normalized = -1.0, weighted = -0.7\n",
      "\tTraining mean reward = 0.0, normalized = -1.0, weighted = -0.1\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 34 = -0.9999999999999999\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 34 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.028, decay_rate=0.993, value=1.0)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=1.0)}\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 90:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.11386286623716069, ConstantSchedule(value=0.114)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=0.052))\n",
      "Score = -0.9999999999999999. Breakdown:\n",
      "\tEvaluation mean reward = 0.04, normalized = -1.0, weighted = -0.7\n",
      "\tTraining mean reward = 0.03, normalized = -1.0, weighted = -0.1\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 90 = -0.9999999999999999\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 56 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.028, decay_rate=0.993, value=1.0)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=1.0)}\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 12:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.11536442599539684, ConstantSchedule(value=0.115)), alpha=ConstantSchedule(value=0.723))\n",
      "Score = -0.9999999999999999. Breakdown:\n",
      "\tEvaluation mean reward = 0.0, normalized = -1.0, weighted = -0.7\n",
      "\tTraining mean reward = 0.0, normalized = -1.0, weighted = -0.1\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 12 = -0.9999999999999999\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 78 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.028, decay_rate=0.993, value=1.0)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=1.0)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d74a32382bb347e7ac7714f55af84abe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab7273ab1c26414ab2957c8a90f20312",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcc60e1e71ba4074a8a165fee811093e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 78:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.0620865541722682, ConstantSchedule(value=0.062)), alpha=ConstantSchedule(value=0.341))\n",
      "Score = -0.9999999999999999. Breakdown:\n",
      "\tEvaluation mean reward = 0.0, normalized = -1.0, weighted = -0.7\n",
      "\tTraining mean reward = 0.0, normalized = -1.0, weighted = -0.1\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 78 = -0.9999999999999999\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 90 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.028, decay_rate=0.993, value=1.0)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=1.0)}\n",
      "Score in the FrozenLakeEnv environment with seed 90:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9949048319493907, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=0.995)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.073, decay_rate=0.964, value=0.073))\n",
      "Score = 0.5980350036213552. Breakdown:\n",
      "\tEvaluation mean reward = 0.73, normalized = 0.7899988299594711, weighted = 0.5529991809716297\n",
      "\tTraining mean reward = 0.71, normalized = 0.3426949069654588, weighted = 0.03426949069654588\n",
      "\tTraining episodes = 2401, normalized = 0.0538316597658981, weighted = 0.01076633195317962\n",
      "Total score across all environments for seed 90 = 0.5980350036213552\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 12 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.999, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.073, decay_rate=0.964, value=1.0)}\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 12:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.09891688511742908, ConstantSchedule(value=0.099)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=0.074))\n",
      "Score = -0.8152018123510852. Breakdown:\n",
      "\tEvaluation mean reward = 0.63, normalized = -0.9866142981514303, weighted = -0.6906300087060012\n",
      "\tTraining mean reward = 0.72, normalized = 0.6133572603953845, weighted = 0.061335726039538456\n",
      "\tTraining episodes = 3951, normalized = -0.9295376484231119, weighted = -0.1859075296846224\n",
      "Total score across all environments for seed 12 = -0.8152018123510852\n",
      "---------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "198132d2f8f243a69ba0cd872a896192",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training on FrozenLakeEnv environment with seed 34 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.999, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.073, decay_rate=0.964, value=1.0)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26d24febf395477dbf83f3d1a1e0413c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score in the FrozenLakeEnv environment with seed 34:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.11386286623716069, ConstantSchedule(value=0.114)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=0.052))\n",
      "Score = -0.9999999999999999. Breakdown:\n",
      "\tEvaluation mean reward = 0.0, normalized = -1.0, weighted = -0.7\n",
      "\tTraining mean reward = 0.0, normalized = -1.0, weighted = -0.1\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fa33a1d76a7409683ef02a41eba7e3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total score across all environments for seed 34 = -0.9999999999999999\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 56 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.999, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.073, decay_rate=0.964, value=1.0)}\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 90:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.11536442599539684, ConstantSchedule(value=0.115)), alpha=ConstantSchedule(value=0.723))\n",
      "Score = -0.9999999999999999. Breakdown:\n",
      "\tEvaluation mean reward = 0.0, normalized = -1.0, weighted = -0.7\n",
      "\tTraining mean reward = 0.0, normalized = -1.0, weighted = -0.1\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 90 = -0.9999999999999999\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 78 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.999, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.073, decay_rate=0.964, value=1.0)}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34714574bcf94b8b92f8e96d6e41d268",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score in the FrozenLakeEnv environment with seed 34:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.0620865541722682, ConstantSchedule(value=0.062)), alpha=ConstantSchedule(value=0.341))\n",
      "Score = -0.9999999999999999. Breakdown:\n",
      "\tEvaluation mean reward = 0.0, normalized = -1.0, weighted = -0.7\n",
      "\tTraining mean reward = 0.0, normalized = -1.0, weighted = -0.1\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 34 = -0.9999999999999999\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 90 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.999, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.073, decay_rate=0.964, value=1.0)}\n",
      "Score in the FrozenLakeEnv environment with seed 12:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.0620865541722682, ConstantSchedule(value=0.062)), alpha=ConstantSchedule(value=0.341))\n",
      "Score = -0.9999999999999999. Breakdown:\n",
      "\tEvaluation mean reward = 0.0, normalized = -1.0, weighted = -0.7\n",
      "\tTraining mean reward = 0.0, normalized = -1.0, weighted = -0.1\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 12 = -0.9999999999999999\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 12 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)), 'alpha': ConstantSchedule(value=0.744)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7339e810385b4dd5afc9a89504d20aa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6799c165e5d04079810b1b5c4cb926a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score in the FrozenLakeEnv environment with seed 78:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.11536442599539684, ConstantSchedule(value=0.115)), alpha=ConstantSchedule(value=0.723))\n",
      "Score = -0.9999999999999999. Breakdown:\n",
      "\tEvaluation mean reward = 0.0, normalized = -1.0, weighted = -0.7\n",
      "\tTraining mean reward = 0.0, normalized = -1.0, weighted = -0.1\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 78 = -0.9999999999999999\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 34 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)), 'alpha': ConstantSchedule(value=0.744)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a9bb68a9a9b4d45b6e94e0d17ecefdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 78:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.11386286623716069, ConstantSchedule(value=0.114)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=0.052))\n",
      "Score = -0.9999999999999999. Breakdown:\n",
      "\tEvaluation mean reward = 0.0, normalized = -1.0, weighted = -0.7\n",
      "\tTraining mean reward = 0.0, normalized = -1.0, weighted = -0.1\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 78 = -0.9999999999999999\n",
      "---------------------------------------------\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 78:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9856096084041313, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.007, decay_rate=0.998, value=0.986)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.098, decay_rate=1.0, value=0.098))\n",
      "Score = 0.5385477709947993. Breakdown:\n",
      "\tEvaluation mean reward = 0.71, normalized = 0.3426949069654588, weighted = 0.23988643487582115\n",
      "\tTraining mean reward = 0.77, normalized = 0.9866142981514305, weighted = 0.09866142981514306\n",
      "\tTraining episodes = 1001, normalized = 0.9999995315191756, weighted = 0.19999990630383513Training on FrozenLakeEnv environment with seed 56 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)), 'alpha': ConstantSchedule(value=0.744)}\n",
      "\n",
      "Total score across all environments for seed 78 = 0.5385477709947993\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 78 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)), 'alpha': ConstantSchedule(value=0.744)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be9b2df95cf34ebdad719b34e0b44d09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score in the FrozenLakeEnv environment with seed 56:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.0620865541722682, ConstantSchedule(value=0.062)), alpha=ConstantSchedule(value=0.341))\n",
      "Score = -0.9999999999999999. Breakdown:\n",
      "\tEvaluation mean reward = 0.0, normalized = -1.0, weighted = -0.7\n",
      "\tTraining mean reward = 0.0, normalized = -1.0, weighted = -0.1\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 56 = -0.9999999999999999\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 90 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)), 'alpha': ConstantSchedule(value=0.744)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5172e52f0a054f5fbe12261f506b8e3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d326dddcfb84e31ba275cba858638a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c086bf9db067465292eac184a6b9e9a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 34:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9880080070034427, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.007, decay_rate=0.998, value=0.988)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.098, decay_rate=1.0, value=0.098))\n",
      "Score = 0.9002437887446174. Breakdown:\n",
      "\tEvaluation mean reward = 0.74, normalized = 0.8913734677347187, weighted = 0.623961427414303\n",
      "\tTraining mean reward = 0.74, normalized = 0.8913734677347187, weighted = 0.08913734677347188\n",
      "\tTraining episodes = 1651, normalized = 0.9357250727842126, weighted = 0.18714501455684251\n",
      "\n",
      "Total score across all environments for seed 34 = 0.9002437887446174\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 12 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.0620865541722682, ConstantSchedule(value=0.062)), 'alpha': ConstantSchedule(value=0.744)}\n",
      "Score in the FrozenLakeEnv environment with seed 90:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9928048042020656, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.007, decay_rate=0.998, value=0.993)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.098, decay_rate=1.0, value=0.098))\n",
      "Score = 0.04867214706863697. Breakdown:\n",
      "\tEvaluation mean reward = 0.69, normalized = -0.34269490696546123, weighted = -0.23988643487582284\n",
      "\tTraining mean reward = 0.76, normalized = 0.9728461661125116, weighted = 0.09728461661125117\n",
      "\tTraining episodes = 1601, normalized = 0.9563698266660432, weighted = 0.19127396533320865\n",
      "Total score across all environments for seed 90 = 0.04867214706863697\n",
      "---------------------------------------------\n",
      "\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 34 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.0620865541722682, ConstantSchedule(value=0.062)), 'alpha': ConstantSchedule(value=0.744)}\n",
      "Score in the FrozenLakeEnv environment with seed 34:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.09891688511742908, ConstantSchedule(value=0.099)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=0.074))\n",
      "Score = -0.9999999985636957. Breakdown:\n",
      "\tEvaluation mean reward = 0.41, normalized = -0.9999999979819588, weighted = -0.6999999985873712\n",
      "\tTraining mean reward = 0.38, normalized = -0.999999999763245, weighted = -0.09999999997632451\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 34 = -0.9999999985636957\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 56 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.0620865541722682, ConstantSchedule(value=0.062)), 'alpha': ConstantSchedule(value=0.744)}\n",
      "Score in the FrozenLakeEnv environment with seed 56:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9121530652930798, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=0.912)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.073, decay_rate=0.964, value=0.073))\n",
      "Score = -0.8251520629712299. Breakdown:\n",
      "\tEvaluation mean reward = 0.65, normalized = -0.9453064264076338, weighted = -0.6617144984853437\n",
      "\tTraining mean reward = 0.7, normalized = 0.0, weighted = 0.0\n",
      "\tTraining episodes = 3501, normalized = -0.8171878224294309, weighted = -0.1634375644858862\n",
      "Total score across all environments for seed 56 = -0.8251520629712299\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 78 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.0620865541722682, ConstantSchedule(value=0.062)), 'alpha': ConstantSchedule(value=0.744)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37b715465c1442b6bc2fe6cf654602bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62a4cf3619494e3c827acd4c12f50fd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86fb2e9da6ac4d58a3821782732ace58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "177f7ae0a0154941b35bf09cfbb3bc93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score in the FrozenLakeEnv environment with seed 56:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.09891688511742908, ConstantSchedule(value=0.099)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=0.074))\n",
      "Score = -0.9999999999999999. Breakdown:\n",
      "\tEvaluation mean reward = 0.06, normalized = -1.0, weighted = -0.7\n",
      "\tTraining mean reward = 0.08, normalized = -1.0, weighted = -0.1\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 56 = -0.9999999999999999\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 90 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.0620865541722682, ConstantSchedule(value=0.062)), 'alpha': ConstantSchedule(value=0.744)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0722fded8c6e4148aca9d0dca9eee8b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score in the FrozenLakeEnv environment with seed 78:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)), alpha=ConstantSchedule(value=0.723))\n",
      "Score = 0.6992769056671188. Breakdown:\n",
      "\tEvaluation mean reward = 0.77, normalized = 0.9866142981514305, weighted = 0.6906300087060013\n",
      "\tTraining mean reward = 0.74, normalized = 0.8913734677347187, weighted = 0.08913734677347188\n",
      "\tTraining episodes = 2801, normalized = -0.4024522490617721, weighted = -0.08049044981235443\n",
      "Total score across all environments for seed 78 = 0.6992769056671188\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 12 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=1.0)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.137, decay_rate=0.998, value=1.0)}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e805081896f149d4ad2006d5d3bfb709",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score in the FrozenLakeEnv environment with seed 56:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9671008414870099, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.028, decay_rate=0.993, value=0.967)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.06, decay_rate=0.994, value=0.06))\n",
      "Score = 0.8797827204649604. Breakdown:\n",
      "\tEvaluation mean reward = 0.77, normalized = 0.9866142981514305, weighted = 0.6906300087060013\n",
      "\tTraining mean reward = 0.73, normalized = 0.7899988299594711, weighted = 0.07899988299594712\n",
      "\tTraining episodes = 2051, normalized = 0.5507641438150594, weighted = 0.1101528287630119\n",
      "Total score across all environments for seed 56 = 0.8797827204649604\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 34 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=1.0)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.137, decay_rate=0.998, value=1.0)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "390614ca32e74a64a9f1129f0b57c3eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score in the FrozenLakeEnv environment with seed 78:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.09891688511742908, ConstantSchedule(value=0.099)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=0.074))\n",
      "Score = -0.9999999999999999. Breakdown:\n",
      "\tEvaluation mean reward = 0.0, normalized = -1.0, weighted = -0.7\n",
      "\tTraining mean reward = 0.0, normalized = -1.0, weighted = -0.1\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 78 = -0.9999999999999999\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 56 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=1.0)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.137, decay_rate=0.998, value=1.0)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "662345e3e66241d4b077e6c419112388",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score in the FrozenLakeEnv environment with seed 90:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.09891688511742908, ConstantSchedule(value=0.099)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=0.074))\n",
      "Score = -0.7656797816031096. Breakdown:\n",
      "\tEvaluation mean reward = 0.65, normalized = -0.9453064264076338, weighted = -0.6617144984853437\n",
      "\tTraining mean reward = 0.75, normalized = 0.9453064264076343, weighted = 0.09453064264076344\n",
      "\tTraining episodes = 4601, normalized = -0.9924796287926463, weighted = -0.19849592575852926\n",
      "Total score across all environments for seed 90 = -0.7656797816031096\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 78 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=1.0)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.137, decay_rate=0.998, value=1.0)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dc9bb9bd3de4024957b8880f2e1c8df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score in the FrozenLakeEnv environment with seed 34:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9098263111295232, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=0.91)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.137, decay_rate=0.998, value=0.137))\n",
      "Score = 0.823961427414303. Breakdown:\n",
      "\tEvaluation mean reward = 0.74, normalized = 0.8913734677347187, weighted = 0.623961427414303\n",
      "\tTraining mean reward = 0.7, normalized = 0.0, weighted = 0.0\n",
      "\tTraining episodes = 651, normalized = 1.0, weighted = 0.2\n",
      "Total score across all environments for seed 34 = 0.823961427414303\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 90 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=1.0)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.137, decay_rate=0.998, value=1.0)}\n",
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 78:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9905652252485234, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.999, value=0.991)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.073, decay_rate=0.964, value=0.073))\n",
      "Score = -0.5777378700161397. Breakdown:\n",
      "\tEvaluation mean reward = 0.62, normalized = -0.993424677228132, weighted = -0.6953972740596923\n",
      "\tTraining mean reward = 0.73, normalized = 0.7899988299594711, weighted = 0.07899988299594712\n",
      "\tTraining episodes = 2301, normalized = 0.19329760523802686, weighted = 0.03865952104760537\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b44a2caf3a1a439faf4ccd37fa9bdee2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total score across all environments for seed 78 = -0.5777378700161397\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 12 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.009, decay_rate=0.988, value=1.0)), 'alpha': ConstantSchedule(value=0.723)}\n",
      "Score in the FrozenLakeEnv environment with seed 90:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.980260504892206, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.028, decay_rate=0.993, value=0.98)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.06, decay_rate=0.994, value=0.06))\n",
      "Score = -0.7276695778008191. Breakdown:\n",
      "\tEvaluation mean reward = 0.55, normalized = -0.9999555506739739, weighted = -0.6999688854717817\n",
      "\tTraining mean reward = 0.7, normalized = 0.0, weighted = 0.0\n",
      "\tTraining episodes = 2551, normalized = -0.13850346164518668, weighted = -0.027700692329037338\n",
      "Total score across all environments for seed 90 = -0.7276695778008191\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 34 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.009, decay_rate=0.988, value=1.0)), 'alpha': ConstantSchedule(value=0.723)}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1c34f4a13ce4ae5936087512a1543e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score in the FrozenLakeEnv environment with seed 90:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9915046831234728, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.999, value=0.992)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.073, decay_rate=0.964, value=0.073))\n",
      "Score = -0.07889099499054586. Breakdown:\n",
      "\tEvaluation mean reward = 0.69, normalized = -0.34269490696546123, weighted = -0.23988643487582284\n",
      "\tTraining mean reward = 0.73, normalized = 0.7899988299594711, weighted = 0.07899988299594712\n",
      "\tTraining episodes = 2151, normalized = 0.40997778444664923, weighted = 0.08199555688932986\n",
      "Total score across all environments for seed 90 = -0.07889099499054586\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e39e10e8c3c14dc5bfc7dc29fce1d0b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 56 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.009, decay_rate=0.988, value=1.0)), 'alpha': ConstantSchedule(value=0.723)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "355dcc2507a74274ab628487c4d85a35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 78:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.993420168297402, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.028, decay_rate=0.993, value=0.993)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.06, decay_rate=0.994, value=0.06))\n",
      "Score = -0.7467484866747448. Breakdown:\n",
      "\tEvaluation mean reward = 0.62, normalized = -0.993424677228132, weighted = -0.6953972740596923\n",
      "\tTraining mean reward = 0.72, normalized = 0.6133572603953845, weighted = 0.061335726039538456\n",
      "\tTraining episodes = 3001, normalized = -0.5634346932729546, weighted = -0.11268693865459092\n",
      "Total score across all environments for seed 78 = -0.7467484866747448\n",
      "---------------------------------------------\n",
      "\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 78 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.009, decay_rate=0.988, value=1.0)), 'alpha': ConstantSchedule(value=0.723)}\n",
      "Score in the FrozenLakeEnv environment with seed 34:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9539411780818139, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.028, decay_rate=0.993, value=0.954)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.06, decay_rate=0.994, value=0.06))\n",
      "Score = 0.5208823777718653. Breakdown:\n",
      "\tEvaluation mean reward = 0.74, normalized = 0.8913734677347187, weighted = 0.623961427414303\n",
      "\tTraining mean reward = 0.71, normalized = 0.3426949069654588, weighted = 0.03426949069654588\n",
      "\tTraining episodes = 3201, normalized = -0.6867427016949178, weighted = -0.13734854033898355\n",
      "Total score across all environments for seed 34 = 0.5208823777718653\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 90 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.009, decay_rate=0.988, value=1.0)), 'alpha': ConstantSchedule(value=0.723)}\n",
      "Score in the FrozenLakeEnv environment with seed 56:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9276218512714218, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.028, decay_rate=0.993, value=0.928)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=0.052))\n",
      "Score = -0.6950562650828433. Breakdown:\n",
      "\tEvaluation mean reward = 0.66, normalized = -0.8913734677347183, weighted = -0.6239614274143027\n",
      "\tTraining mean reward = 0.7, normalized = 0.0, weighted = 0.0\n",
      "\tTraining episodes = 2751, normalized = -0.35547418834270317, weighted = -0.07109483766854063\n",
      "Total score across all environments for seed 56 = -0.6950562650828433\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 12 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.023, decay_rate=0.993, value=1.0)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.137, decay_rate=0.998, value=1.0)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "741e7c34a1a5478da34982de0e60f8e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a939dfa0ec9d48358974d1e7e5a91be9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "647680c06b124d59b577021fa44214d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score in the FrozenLakeEnv environment with seed 12:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)), alpha=ConstantSchedule(value=0.723))\n",
      "Score = -0.9999999999999999. Breakdown:\n",
      "\tEvaluation mean reward = 0.0, normalized = -1.0, weighted = -0.7\n",
      "\tTraining mean reward = 0.0, normalized = -1.0, weighted = -0.1\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 12 = -0.9999999999999999\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 34 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.023, decay_rate=0.993, value=1.0)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.137, decay_rate=0.998, value=1.0)}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22ef6b3846ff4c419815e79863538f01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score in the FrozenLakeEnv environment with seed 34:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)), alpha=ConstantSchedule(value=0.723))\n",
      "Score = -0.9999999999999999. Breakdown:\n",
      "\tEvaluation mean reward = 0.0, normalized = -1.0, weighted = -0.7\n",
      "\tTraining mean reward = 0.0, normalized = -1.0, weighted = -0.1\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 34 = -0.9999999999999999\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 56 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.023, decay_rate=0.993, value=1.0)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.137, decay_rate=0.998, value=1.0)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e110e46c23a14c6d95183d5d3a9d511a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score in the FrozenLakeEnv environment with seed 78:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.993420168297402, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.028, decay_rate=0.993, value=0.993)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=0.052))\n",
      "Score = -0.7843741244737557. Breakdown:\n",
      "\tEvaluation mean reward = 0.56, normalized = -0.9999092042625951, weighted = -0.6999364429838165\n",
      "\tTraining mean reward = 0.73, normalized = 0.7899988299594711, weighted = 0.07899988299594712\n",
      "\tTraining episodes = 3501, normalized = -0.8171878224294309, weighted = -0.1634375644858862\n",
      "Total score across all environments for seed 78 = -0.7843741244737557\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 78 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.023, decay_rate=0.993, value=1.0)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.137, decay_rate=0.998, value=1.0)}\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 56:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)), alpha=ConstantSchedule(value=0.723))\n",
      "Score = -0.9999999999999999. Breakdown:\n",
      "\tEvaluation mean reward = 0.0, normalized = -1.0, weighted = -0.7\n",
      "\tTraining mean reward = 0.0, normalized = -1.0, weighted = -0.1\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 56 = -0.9999999999999999\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 90 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.023, decay_rate=0.993, value=1.0)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.137, decay_rate=0.998, value=1.0)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0e41f6de9244ca29b04fd8675b088d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea5b2d7cc7254aa6aefb03dabcf2af1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score in the FrozenLakeEnv environment with seed 90:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9671008414870099, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.028, decay_rate=0.993, value=0.967)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=0.052))\n",
      "Score = -0.32766165497319394. Breakdown:\n",
      "\tEvaluation mean reward = 0.69, normalized = -0.34269490696546123, weighted = -0.23988643487582284\n",
      "\tTraining mean reward = 0.73, normalized = 0.7899988299594711, weighted = 0.07899988299594712\n",
      "\tTraining episodes = 3551, normalized = -0.8338755154665909, weighted = -0.1667751030933182\n",
      "Total score across all environments for seed 90 = -0.32766165497319394\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 12 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=1.0)), 'alpha': ConstantSchedule(value=0.723)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eef524d8c7894c0994664144b0707073",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 78:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)), alpha=ConstantSchedule(value=0.744))\n",
      "Score = 0.15055910250693386. Breakdown:\n",
      "\tEvaluation mean reward = 0.71, normalized = 0.3426949069654588, weighted = 0.23988643487582115\n",
      "\tTraining mean reward = 0.7, normalized = 0.0, weighted = 0.0\n",
      "\tTraining episodes = 2851, normalized = -0.4466366618444364, weighted = -0.08932733236888729\n",
      "Total score across all environments for seed 78 = 0.15055910250693386\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 34 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=1.0)), 'alpha': ConstantSchedule(value=0.723)}\n",
      "Score in the FrozenLakeEnv environment with seed 78:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9974491625889466, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=0.997)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.137, decay_rate=0.998, value=0.137))\n",
      "Score = -0.49883073457162597. Breakdown:\n",
      "\tEvaluation mean reward = 0.61, normalized = -0.9967756945029475, weighted = -0.6977429861520632\n",
      "\tTraining mean reward = 0.7, normalized = 0.0, weighted = 0.0\n",
      "\tTraining episodes = 1401, normalized = 0.9945612579021861, weighted = 0.19891225158043724\n",
      "Total score across all environments for seed 78 = -0.49883073457162597\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 56 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=1.0)), 'alpha': ConstantSchedule(value=0.723)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5297cd1b583c4add9efcb018fef5db69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e21990464b749aa8719e2ea98cb50c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score in the FrozenLakeEnv environment with seed 90:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)), alpha=ConstantSchedule(value=0.723))\n",
      "Score = -0.9999999999999999. Breakdown:\n",
      "\tEvaluation mean reward = 0.0, normalized = -1.0, weighted = -0.7\n",
      "\tTraining mean reward = 0.0, normalized = -1.0, weighted = -0.1\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 90 = -0.9999999999999999\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 78 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=1.0)), 'alpha': ConstantSchedule(value=0.723)}\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 12:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.980260504892206, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.028, decay_rate=0.993, value=0.98)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.06, decay_rate=0.994, value=0.06))\n",
      "Score = -0.8916036805577638. Breakdown:\n",
      "\tEvaluation mean reward = 0.55, normalized = -0.9999555506739739, weighted = -0.6999688854717817\n",
      "\tTraining mean reward = 0.7, normalized = 0.0, weighted = 0.0\n",
      "\tTraining episodes = 4151, normalized = -0.9581739754299106, weighted = -0.19163479508598213\n",
      "Total score across all environments for seed 12 = -0.8916036805577638\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 90 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=1.0)), 'alpha': ConstantSchedule(value=0.723)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ae26b56c99c42fe990a8e078ddcbc98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58bb2636d99947469aadd68e78d2d1fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 34:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9546299190640855, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.023, decay_rate=0.993, value=0.955)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.137, decay_rate=0.998, value=0.137))\n",
      "Score = 0.9320013463195634. Breakdown:\n",
      "\tEvaluation mean reward = 0.79, normalized = 0.9967756945029476, weighted = 0.6977429861520632\n",
      "\tTraining mean reward = 0.71, normalized = 0.3426949069654588, weighted = 0.03426949069654588\n",
      "\tTraining episodes = 1151, normalized = 0.999944347354772, weighted = 0.1999888694709544\n",
      "Total score across all environments for seed 34 = 0.9320013463195634\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 12 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.98, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=1.0)}\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 56:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9257080054952995, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.009, decay_rate=0.988, value=0.926)), alpha=ConstantSchedule(value=0.723))\n",
      "Score = 0.8877149908164212. Breakdown:\n",
      "\tEvaluation mean reward = 0.78, normalized = 0.9934246772281319, weighted = 0.6953972740596923\n",
      "\tTraining mean reward = 0.71, normalized = 0.3426949069654588, weighted = 0.03426949069654588\n",
      "\tTraining episodes = 1851, normalized = 0.7902411303009154, weighted = 0.1580482260601831\n",
      "Total score across all environments for seed 56 = 0.8877149908164212\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 34 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.98, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=1.0)}\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 78:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.7152140210653148, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.009, decay_rate=0.988, value=0.715)), alpha=ConstantSchedule(value=0.723))\n",
      "Score = 0.9815815434895048. Breakdown:\n",
      "\tEvaluation mean reward = 0.77, normalized = 0.9866142981514305, weighted = 0.6906300087060013\n",
      "\tTraining mean reward = 0.79, normalized = 0.9967756945029476, weighted = 0.09967756945029477\n",
      "\tTraining episodes = 1601, normalized = 0.9563698266660432, weighted = 0.19127396533320865\n",
      "Total score across all environments for seed 78 = 0.9815815434895048\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 56 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.98, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=1.0)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e40e986d7954980917e100fcf6f7d77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score in the FrozenLakeEnv environment with seed 90:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.900944007327066, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.009, decay_rate=0.988, value=0.901)), alpha=ConstantSchedule(value=0.723))\n",
      "Score = 0.9164789849487043. Breakdown:\n",
      "\tEvaluation mean reward = 0.74, normalized = 0.8913734677347187, weighted = 0.623961427414303\n",
      "\tTraining mean reward = 0.75, normalized = 0.9453064264076343, weighted = 0.09453064264076344\n",
      "\tTraining episodes = 1451, normalized = 0.9899345744681884, weighted = 0.1979869148936377\n",
      "Total score across all environments for seed 90 = 0.9164789849487043\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 78 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.98, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=1.0)}\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 34:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9342016829740198, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.028, decay_rate=0.993, value=0.934)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=0.052))\n",
      "Score = 0.48900198515424137. Breakdown:\n",
      "\tEvaluation mean reward = 0.74, normalized = 0.8913734677347187, weighted = 0.623961427414303\n",
      "\tTraining mean reward = 0.72, normalized = 0.6133572603953845, weighted = 0.061335726039538456\n",
      "\tTraining episodes = 4401, normalized = -0.9814758414980008, weighted = -0.19629516829960017"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b3a06621d3540ada7741a3eb93e12aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total score across all environments for seed 34 = 0.48900198515424137\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 90 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.98, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=1.0)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96d766ab2c6643aabfbf3bcfe868b732",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0808eda25bb64029ae6d342bb39e1391",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score in the FrozenLakeEnv environment with seed 12:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.996215354221057, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.999, value=0.996)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.073, decay_rate=0.964, value=0.073))\n",
      "Score = 0.2777120432886926. Breakdown:\n",
      "\tEvaluation mean reward = 0.72, normalized = 0.6133572603953845, weighted = 0.42935008227676913\n",
      "\tTraining mean reward = 0.71, normalized = 0.3426949069654588, weighted = 0.03426949069654588\n",
      "\tTraining episodes = 3951, normalized = -0.9295376484231119, weighted = -0.1859075296846224\n",
      "Total score across all environments for seed 12 = 0.2777120432886926\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 12 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.09, decay_rate=0.996, value=1.0)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b49c843a36e494188fdad3058682e7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score in the FrozenLakeEnv environment with seed 90:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.0620865541722682, ConstantSchedule(value=0.062)), alpha=ConstantSchedule(value=0.744))\n",
      "Score = -0.5552142792831369. Breakdown:\n",
      "\tEvaluation mean reward = 0.68, normalized = -0.613357260395381, weighted = -0.42935008227676663\n",
      "\tTraining mean reward = 0.7, normalized = 0.0, weighted = 0.0\n",
      "\tTraining episodes = 3101, normalized = -0.6293209850318515, weighted = -0.1258641970063703\n",
      "Total score across all environments for seed 90 = -0.5552142792831369\n",
      "---------------------------------------------\n",
      "\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 34 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.09, decay_rate=0.996, value=1.0)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c40d29167f54b81a8f6fea64737d5e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score in the FrozenLakeEnv environment with seed 12:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9974491625889466, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=0.997)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.137, decay_rate=0.998, value=0.137))\n",
      "Score = -0.7368101149414107. Breakdown:\n",
      "\tEvaluation mean reward = 0.54, normalized = -0.9999782399563084, weighted = -0.6999847679694159\n",
      "\tTraining mean reward = 0.71, normalized = 0.3426949069654588, weighted = 0.03426949069654588\n",
      "\tTraining episodes = 2751, normalized = -0.35547418834270317, weighted = -0.07109483766854063\n",
      "Total score across all environments for seed 12 = -0.7368101149414107\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 56 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.09, decay_rate=0.996, value=1.0)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ebe77ba9025497d885a34efefd13c7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f727c59f2e54ab69dd70bbaca6056af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score in the FrozenLakeEnv environment with seed 12:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9483187405383926, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.023, decay_rate=0.993, value=0.948)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.137, decay_rate=0.998, value=0.137))\n",
      "Score = 0.6725085390352913. Breakdown:\n",
      "\tEvaluation mean reward = 0.72, normalized = 0.6133572603953845, weighted = 0.42935008227676913\n",
      "\tTraining mean reward = 0.72, normalized = 0.6133572603953845, weighted = 0.061335726039538456\n",
      "\tTraining episodes = 1701, normalized = 0.9091136535949187, weighted = 0.18182273071898375\n",
      "Total score across all environments for seed 12 = 0.6725085390352913\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 78 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.09, decay_rate=0.996, value=1.0)}\n",
      "Score in the FrozenLakeEnv environment with seed 90:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9747824477447575, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=0.975)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.137, decay_rate=0.998, value=0.137))\n",
      "Score = -0.5097414759226098. Breakdown:\n",
      "\tEvaluation mean reward = 0.6, normalized = -0.9984202681165271, weighted = -0.6988941876815689\n",
      "\tTraining mean reward = 0.73, normalized = 0.7899988299594711, weighted = 0.07899988299594712\n",
      "\tTraining episodes = 2051, normalized = 0.5507641438150594, weighted = 0.1101528287630119\n",
      "Total score across all environments for seed 90 = -0.5097414759226098\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 90 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.09, decay_rate=0.996, value=1.0)}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a7f96ca5c054540adc63041e47bec36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c4bd8e40a29456b88f8fe86d3484b46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score in the FrozenLakeEnv environment with seed 12:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9752360018317665, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.009, decay_rate=0.988, value=0.975)), alpha=ConstantSchedule(value=0.723))\n",
      "Score = 0.3296526498249479. Breakdown:\n",
      "\tEvaluation mean reward = 0.71, normalized = 0.3426949069654588, weighted = 0.23988643487582115\n",
      "\tTraining mean reward = 0.73, normalized = 0.7899988299594711, weighted = 0.07899988299594712\n",
      "\tTraining episodes = 2401, normalized = 0.0538316597658981, weighted = 0.01076633195317962\n",
      "Total score across all environments for seed 12 = 0.3296526498249479\n",
      "---------------------------------------------\n",
      "\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 12 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=1.0)}\n",
      "Score in the FrozenLakeEnv environment with seed 34:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.950472003663533, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.009, decay_rate=0.988, value=0.95)), alpha=ConstantSchedule(value=0.723))\n",
      "Score = 0.8504529976663158. Breakdown:\n",
      "\tEvaluation mean reward = 0.79, normalized = 0.9967756945029476, weighted = 0.6977429861520632\n",
      "\tTraining mean reward = 0.79, normalized = 0.9967756945029476, weighted = 0.09967756945029477\n",
      "\tTraining episodes = 2251, normalized = 0.26516221031978904, weighted = 0.05303244206395781\n",
      "Total score across all environments for seed 34 = 0.8504529976663158\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 34 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=1.0)}\n",
      "Score in the FrozenLakeEnv environment with seed 12:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9473613463792159, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.028, decay_rate=0.993, value=0.947)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=0.052))\n",
      "Score = -0.9999688854481062. Breakdown:\n",
      "\tEvaluation mean reward = 0.55, normalized = -0.9999555506739739, weighted = -0.6999688854717817\n",
      "\tTraining mean reward = 0.38, normalized = -0.999999999763245, weighted = -0.09999999997632451\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 12 = -0.9999688854481062\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 56 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=1.0)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9fe0311c7fa4a1d8d603cb5c8ee2a94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f56e3e8c7205476e82773c115a461a07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87daf2459f824845b6a9a3a94f5631dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score in the FrozenLakeEnv environment with seed 56:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9923669914836164, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=0.992)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.137, decay_rate=0.998, value=0.137))\n",
      "Score = 0.8362151385443173. Breakdown:\n",
      "\tEvaluation mean reward = 0.8, normalized = 0.9984202681165271, weighted = 0.6988941876815689\n",
      "\tTraining mean reward = 0.77, normalized = 0.9866142981514305, weighted = 0.09866142981514306\n",
      "\tTraining episodes = 2301, normalized = 0.19329760523802686, weighted = 0.03865952104760537\n",
      "Total score across all environments for seed 56 = 0.8362151385443173\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 78 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=1.0)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbe79ab2e8e74137aa47af3d5bce595b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score in the FrozenLakeEnv environment with seed 90:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.8874568572684327, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.023, decay_rate=0.993, value=0.887)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.137, decay_rate=0.998, value=0.137))\n",
      "Score = 0.00859430572055813. Breakdown:\n",
      "\tEvaluation mean reward = 0.69, normalized = -0.34269490696546123, weighted = -0.23988643487582284\n",
      "\tTraining mean reward = 0.72, normalized = 0.6133572603953845, weighted = 0.061335726039538456\n",
      "\tTraining episodes = 1651, normalized = 0.9357250727842126, weighted = 0.18714501455684251\n",
      "Total score across all environments for seed 90 = 0.00859430572055813\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 90 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=1.0)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc37677f014547c4bb1a1153591f7a78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score in the FrozenLakeEnv environment with seed 12:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)), alpha=ConstantSchedule(value=0.744))\n",
      "Score = -0.9999999999999999. Breakdown:\n",
      "\tEvaluation mean reward = 0.0, normalized = -1.0, weighted = -0.7\n",
      "\tTraining mean reward = 0.0, normalized = -1.0, weighted = -0.1\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 12 = -0.9999999999999999\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 12 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=1.0)}\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 56:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9546299190640855, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.023, decay_rate=0.993, value=0.955)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.137, decay_rate=0.998, value=0.137))\n",
      "Score = -0.5651558290056024. Breakdown:\n",
      "\tEvaluation mean reward = 0.66, normalized = -0.8913734677347183, weighted = -0.6239614274143027\n",
      "\tTraining mean reward = 0.71, normalized = 0.3426949069654588, weighted = 0.03426949069654588\n",
      "\tTraining episodes = 2351, normalized = 0.12268053856077255, weighted = 0.02453610771215451\n",
      "Total score across all environments for seed 56 = -0.5651558290056024\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 34 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=1.0)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0928bb2627eb40eb89995c176dcd55b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 12:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9992783472680413, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=0.999)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.09, decay_rate=0.996, value=0.09))\n",
      "Score = 0.7238801336534844. Breakdown:\n",
      "\tEvaluation mean reward = 0.72, normalized = 0.6133572603953845, weighted = 0.42935008227676913\n",
      "\tTraining mean reward = 0.75, normalized = 0.9453064264076343, weighted = 0.09453064264076344\n",
      "\tTraining episodes = 1051, normalized = 0.9999970436797587, weighted = 0.19999940873595176\n",
      "Total score across all environments for seed 12 = 0.7238801336534844\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 56 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=1.0)}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd2f4a5be009480e92773b0c29c930ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score in the FrozenLakeEnv environment with seed 56:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)), alpha=ConstantSchedule(value=0.744))\n",
      "Score = -0.9999999999999999. Breakdown:\n",
      "\tEvaluation mean reward = 0.0, normalized = -1.0, weighted = -0.7\n",
      "\tTraining mean reward = 0.0, normalized = -1.0, weighted = -0.1\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2Score in the FrozenLakeEnv environment with seed 34:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9858812711646208, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.999, value=0.986)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.073, decay_rate=0.964, value=0.073))\n",
      "Score = -0.9999997291668844. Breakdown:\n",
      "\tEvaluation mean reward = 0.48, normalized = -0.9999997004961856, weighted = -0.6999997903473298\n",
      "\tTraining mean reward = 0.49, normalized = -0.9999993881955461, weighted = -0.09999993881955462\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "\n",
      "\n",
      "Total score across all environments for seed 34 = -0.9999997291668844\n",
      "Total score across all environments for seed 56 = -0.9999999999999999\n",
      "---------------------------------------------\n",
      "---------------------------------------------\n",
      "\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 78 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=1.0)}\n",
      "Training on FrozenLakeEnv environment with seed 90 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)), 'alpha': LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=1.0)}\n",
      "Score in the FrozenLakeEnv environment with seed 78:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9868214553045994, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.023, decay_rate=0.993, value=0.987)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.137, decay_rate=0.998, value=0.137))\n",
      "Score = -0.4621149963175191. Breakdown:\n",
      "\tEvaluation mean reward = 0.62, normalized = -0.993424677228132, weighted = -0.6953972740596923\n",
      "\tTraining mean reward = 0.76, normalized = 0.9728461661125116, weighted = 0.09728461661125117\n",
      "\tTraining episodes = 1951, normalized = 0.6799883056546103, weighted = 0.13599766113092207\n",
      "Total score across all environments for seed 78 = -0.4621149963175191\n",
      "\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 12 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)), 'alpha': ConstantSchedule(value=0.341)}\n",
      "Score in the FrozenLakeEnv environment with seed 34:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)), alpha=ConstantSchedule(value=0.744))\n",
      "Score = -0.9999999999999999. Breakdown:\n",
      "\tEvaluation mean reward = 0.0, normalized = -1.0, weighted = -0.7\n",
      "\tTraining mean reward = 0.0, normalized = -1.0, weighted = -0.1\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 34 = -0.9999999999999999\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 34 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)), 'alpha': ConstantSchedule(value=0.341)}\n",
      "Score in the FrozenLakeEnv environment with seed 90:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)), alpha=ConstantSchedule(value=0.744))\n",
      "Score = -0.9999999999999999. Breakdown:\n",
      "\tEvaluation mean reward = 0.0, normalized = -1.0, weighted = -0.7\n",
      "\tTraining mean reward = 0.0, normalized = -1.0, weighted = -0.1\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 90 = -0.9999999999999999\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 56 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)), 'alpha': ConstantSchedule(value=0.341)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a67740e518dd42549992d662e0769fe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeeb1f4cc6f9435c91e1f127ade11b71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d6794de721640a28351bd3554b0587c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e6a92734c064f45b3e0555e29bb09e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51484dd3ef504eb3991e0fdd56810794",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b7e9fd5b0b446b6be091e426d2c5d90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score in the FrozenLakeEnv environment with seed 56:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9990524927507252, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.999, value=0.999)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.073, decay_rate=0.964, value=0.073))\n",
      "Score = 0.3906300087543639. Breakdown:\n",
      "\tEvaluation mean reward = 0.77, normalized = 0.9866142981514305, weighted = 0.6906300087060013\n",
      "\tTraining mean reward = 0.39, normalized = -0.9999999995163743, weighted = -0.09999999995163744\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 56 = 0.3906300087543639\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 78 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)), 'alpha': ConstantSchedule(value=0.341)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f29f0ed58c0410c858b0f6be5ee928b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score in the FrozenLakeEnv environment with seed 78:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9992783472680413, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=0.999)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.09, decay_rate=0.996, value=0.09))\n",
      "Score = 0.7872658100904776. Breakdown:\n",
      "\tEvaluation mean reward = 0.73, normalized = 0.7899988299594711, weighted = 0.5529991809716297\n",
      "\tTraining mean reward = 0.71, normalized = 0.3426949069654588, weighted = 0.03426949069654588\n",
      "\tTraining episodes = 1101, normalized = 0.9999856921115104, weighted = 0.1999971384223021\n",
      "Total score across all environments for seed 78 = 0.7872658100904776\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 90 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)), 'alpha': ConstantSchedule(value=0.341)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18e1badb13184fae963931f245c7f16e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score in the FrozenLakeEnv environment with seed 78:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.2670028080521689, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.98, value=0.267)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=0.074))\n",
      "Score = 0.8429345761199813. Breakdown:\n",
      "\tEvaluation mean reward = 0.73, normalized = 0.7899988299594711, weighted = 0.5529991809716297\n",
      "\tTraining mean reward = 0.77, normalized = 0.9866142981514305, weighted = 0.09866142981514306\n",
      "\tTraining episodes = 1601, normalized = 0.9563698266660432, weighted = 0.19127396533320865\n",
      "Total score across all environments for seed 78 = 0.8429345761199813\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 12 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=1.0)), 'alpha': ConstantSchedule(value=0.603)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d4e3e0309f0422f8899e40cec01ee8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score in the FrozenLakeEnv environment with seed 34:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9998797245446736, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=1.0)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=0.074))\n",
      "Score = 0.9547208291936955. Breakdown:\n",
      "\tEvaluation mean reward = 0.75, normalized = 0.9453064264076343, weighted = 0.6617144984853439\n",
      "\tTraining mean reward = 0.77, normalized = 0.9866142981514305, weighted = 0.09866142981514306\n",
      "\tTraining episodes = 1551, normalized = 0.9717245044660427, weighted = 0.19434490089320855\n",
      "Total score across all environments for seed 34 = 0.9547208291936955\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 34 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=1.0)), 'alpha': ConstantSchedule(value=0.603)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdf4f9f4ecc847e693e155047d016d51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score in the FrozenLakeEnv environment with seed 34:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.0620865541722682, ConstantSchedule(value=0.062)), alpha=ConstantSchedule(value=0.744))\n",
      "Score = -0.9999999999999999. Breakdown:\n",
      "\tEvaluation mean reward = 0.0, normalized = -1.0, weighted = -0.7\n",
      "\tTraining mean reward = 0.0, normalized = -1.0, weighted = -0.1\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 34 = -0.9999999999999999\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 56 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=1.0)), 'alpha': ConstantSchedule(value=0.603)}\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 12:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.0620865541722682, ConstantSchedule(value=0.062)), alpha=ConstantSchedule(value=0.744))\n",
      "Score = -0.9999999999999999. Breakdown:\n",
      "\tEvaluation mean reward = 0.0, normalized = -1.0, weighted = -0.7\n",
      "\tTraining mean reward = 0.0, normalized = -1.0, weighted = -0.1\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 12 = -0.9999999999999999\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 78 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=1.0)), 'alpha': ConstantSchedule(value=0.603)}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a029a70cddf04b80889eb8f71969c0cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score in the FrozenLakeEnv environment with seed 90:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9995188981786942, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=1.0)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.09, decay_rate=0.996, value=0.09))\n",
      "Score = -0.4451332947793161. Breakdown:\n",
      "\tEvaluation mean reward = 0.61, normalized = -0.9967756945029475, weighted = -0.6977429861520632\n",
      "\tTraining mean reward = 0.72, normalized = 0.6133572603953845, weighted = 0.061335726039538456\n",
      "\tTraining episodes = 1601, normalized = 0.9563698266660432, weighted = 0.19127396533320865\n",
      "Total score across all environments for seed 90 = -0.4451332947793161\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 90 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=1.0)), 'alpha': ConstantSchedule(value=0.603)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d6f735b8d1e4a7b802bccfe56b57172",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a7fec996d7b4b42a5b7c414aed1c80c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score in the FrozenLakeEnv environment with seed 78:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.0620865541722682, ConstantSchedule(value=0.062)), alpha=ConstantSchedule(value=0.744))\n",
      "Score = -0.9999999999999999. Breakdown:\n",
      "\tEvaluation mean reward = 0.0, normalized = -1.0, weighted = -0.7\n",
      "\tTraining mean reward = 0.0, normalized = -1.0, weighted = -0.1\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 78 = -0.9999999999999999\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 12 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.999, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.09, decay_rate=0.996, value=1.0)}\n",
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 12:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.8167507020130422, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.98, value=0.817)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=0.074))\n",
      "Score = -0.48497134134491254. Breakdown:\n",
      "\tEvaluation mean reward = 0.55, normalized = -0.9999555506739739, weighted = -0.6999688854717817\n",
      "\tTraining mean reward = 0.73, normalized = 0.7899988299594711, weighted = 0.07899988299594712\n",
      "\tTraining episodes = 1951, normalized = 0.6799883056546103, weighted = 0.13599766113092207\n",
      "Total score across all environments for seed 12 = -0.48497134134491254\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 34 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.999, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.09, decay_rate=0.996, value=1.0)}\n",
      "Score in the FrozenLakeEnv environment with seed 56:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.0620865541722682, ConstantSchedule(value=0.062)), alpha=ConstantSchedule(value=0.744))\n",
      "Score = -0.9999999999999999. Breakdown:\n",
      "\tEvaluation mean reward = 0.0, normalized = -1.0, weighted = -0.7\n",
      "\tTraining mean reward = 0.0, normalized = -1.0, weighted = -0.1\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 56 = -0.9999999999999999\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 56 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.999, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.09, decay_rate=0.996, value=1.0)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14f19839bfe049548f293accdfda1ee9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b724976f77f246e3830c649956b303de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b22ab49f22d42d0a6255b21e9b232f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score in the FrozenLakeEnv environment with seed 34:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9429479294766345, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=0.943)), alpha=ConstantSchedule(value=0.723))\n",
      "Score = 0.6838881012421132. Breakdown:\n",
      "\tEvaluation mean reward = 0.77, normalized = 0.9866142981514305, weighted = 0.6906300087060013\n",
      "\tTraining mean reward = 0.77, normalized = 0.9866142981514305, weighted = 0.09866142981514306\n",
      "\tTraining episodes = 2951, normalized = -0.5270166863951559, weighted = -0.10540333727903117\n",
      "Total score across all environments for seed 34 = 0.6838881012421132\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 78 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.999, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.09, decay_rate=0.996, value=1.0)}\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42334f9b37a948d5a6c698d299500aab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score in the FrozenLakeEnv environment with seed 56:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9986769699914091, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=0.999)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=0.074))\n",
      "Score = 0.8621185635085516. Breakdown:\n",
      "\tEvaluation mean reward = 0.77, normalized = 0.9866142981514305, weighted = 0.6906300087060013\n",
      "\tTraining mean reward = 0.72, normalized = 0.6133572603953845, weighted = 0.061335726039538456\n",
      "\tTraining episodes = 2051, normalized = 0.5507641438150594, weighted = 0.1101528287630119\n",
      "Score in the FrozenLakeEnv environment with seed 34:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9987972454467355, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=0.999)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.09, decay_rate=0.996, value=0.09))\n",
      "Score = 0.8337918256276098. Breakdown:\n",
      "\tEvaluation mean reward = 0.74, normalized = 0.8913734677347187, weighted = 0.623961427414303\n",
      "\tTraining mean reward = 0.79, normalized = 0.9967756945029476, weighted = 0.09967756945029477\n",
      "\tTraining episodes = 2051, normalized = 0.5507641438150594, weighted = 0.1101528287630119Total score across all environments for seed 56 = 0.8621185635085516\n",
      "\n",
      "---------------------------------------------\n",
      "Total score across all environments for seed 34 = 0.8337918256276098\n",
      "\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 12 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.996, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=1.0)}\n",
      "Training on FrozenLakeEnv environment with seed 90 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.999, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.09, decay_rate=0.996, value=1.0)}\n",
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 90:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9974491625889466, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=0.997)), alpha=ConstantSchedule(value=0.723))\n",
      "Score = -0.61752765193846. Breakdown:\n",
      "\tEvaluation mean reward = 0.67, normalized = -0.7899988299594689, weighted = -0.5529991809716281\n",
      "\tTraining mean reward = 0.72, normalized = 0.6133572603953845, weighted = 0.061335726039538456\n",
      "\tTraining episodes = 3101, normalized = -0.6293209850318515, weighted = -0.1258641970063703\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af840e7591cc4d4e986d6824639262ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total score across all environments for seed 90 = -0.61752765193846\n",
      "---------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38f0388d596843cc83606afa62e52c02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training on FrozenLakeEnv environment with seed 34 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.996, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=1.0)}\n",
      "Score in the FrozenLakeEnv environment with seed 56:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.8778338013420282, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.98, value=0.878)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=0.074))\n",
      "Score = -0.5380895936626098. Breakdown:\n",
      "\tEvaluation mean reward = 0.66, normalized = -0.8913734677347183, weighted = -0.6239614274143027\n",
      "\tTraining mean reward = 0.72, normalized = 0.6133572603953845, weighted = 0.061335726039538456\n",
      "\tTraining episodes = 2351, normalized = 0.12268053856077255, weighted = 0.02453610771215451\n",
      "Total score across all environments for seed 56 = -0.5380895936626098\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 56 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.996, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=1.0)}\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 12:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9987972454467355, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=0.999)), alpha=ConstantSchedule(value=0.603))\n",
      "Score = -0.13481944045733907. Breakdown:\n",
      "\tEvaluation mean reward = 0.68, normalized = -0.613357260395381, weighted = -0.42935008227676663\n",
      "\tTraining mean reward = 0.75, normalized = 0.9453064264076343, weighted = 0.09453064264076344\n",
      "\tTraining episodes = 901, normalized = 0.9999999958933206, weighted = 0.19999999917866412\n",
      "Total score across all environments for seed 12 = -0.13481944045733907\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 78 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.996, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=1.0)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0edeb327842445ba9857fa9d1b7181d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b0047cf70d1430590c206142fc34fb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 12:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9990377963573884, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=0.999)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=0.074))\n",
      "Score = -0.2973177572168617. Breakdown:\n",
      "\tEvaluation mean reward = 0.68, normalized = -0.613357260395381, weighted = -0.42935008227676663\n",
      "\tTraining mean reward = 0.73, normalized = 0.7899988299594711, weighted = 0.07899988299594712\n",
      "\tTraining episodes = 2251, normalized = 0.26516221031978904, weighted = 0.05303244206395781\n",
      "Total score across all environments for seed 12 = -0.2973177572168617\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 90 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.996, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=1.0)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36f36bbb315c40f193366ea4961b56d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score in the FrozenLakeEnv environment with seed 34:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9995188981786942, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=1.0)), alpha=ConstantSchedule(value=0.603))\n",
      "Score = 0.8143349070111581. Breakdown:\n",
      "\tEvaluation mean reward = 0.73, normalized = 0.7899988299594711, weighted = 0.5529991809716297\n",
      "\tTraining mean reward = 0.72, normalized = 0.6133572603953845, weighted = 0.061335726039538456\n",
      "\tTraining episodes = 751, normalized = 0.9999999999999498, weighted = 0.19999999999998996\n",
      "Total score across all environments for seed 34 = 0.8143349070111581\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 12 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.996, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.073, decay_rate=0.964, value=1.0)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb07b98c7b834ff18d80543d6f2f7f5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21f2adac4c734c9da59848b882f60121",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score in the FrozenLakeEnv environment with seed 78:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9974491625889466, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=0.997)), alpha=ConstantSchedule(value=0.723))\n",
      "Score = 0.6292508551642859. Breakdown:\n",
      "\tEvaluation mean reward = 0.75, normalized = 0.9453064264076343, weighted = 0.6617144984853439\n",
      "\tTraining mean reward = 0.78, normalized = 0.9934246772281319, weighted = 0.09934246772281319\n",
      "\tTraining episodes = 3151, normalized = -0.6590305552193557, weighted = -0.13180611104387116\n",
      "Total score across all environments for seed 78 = 0.6292508551642859\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 34 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.996, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.073, decay_rate=0.964, value=1.0)}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29e0db8178af413290aa78f53eeca6f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score in the FrozenLakeEnv environment with seed 56:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9997594490893471, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=1.0)), alpha=ConstantSchedule(value=0.603))\n",
      "Score = 0.9567330000983009. Breakdown:\n",
      "\tEvaluation mean reward = 0.78, normalized = 0.9934246772281319, weighted = 0.6953972740596923\n",
      "\tTraining mean reward = 0.72, normalized = 0.6133572603953845, weighted = 0.061335726039538456\n",
      "\tTraining episodes = 801, normalized = 0.9999999999953508, weighted = 0.19999999999907017\n",
      "Total score across all environments for seed 56 = 0.9567330000983009\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 56 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.996, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.073, decay_rate=0.964, value=1.0)}\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 78:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9993986227233678, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=0.999)), alpha=ConstantSchedule(value=0.603))\n",
      "Score = 0.5012221501883594. Breakdown:\n",
      "\tEvaluation mean reward = 0.71, normalized = 0.3426949069654588, weighted = 0.23988643487582115\n",
      "\tTraining mean reward = 0.72, normalized = 0.6133572603953845, weighted = 0.061335726039538456\n",
      "\tTraining episodes = 951, normalized = 0.9999999463649991, weighted = 0.19999998927299983\n",
      "Total score across all environments for seed 78 = 0.5012221501883594\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 78 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.996, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.073, decay_rate=0.964, value=1.0)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bae3dc4efad4ef3a0a75fd66cc5c7c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd3be7314aa84a5bb8babb3be59ae98b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score in the FrozenLakeEnv environment with seed 90:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9977147663487975, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=0.998)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=0.074))\n",
      "Score = -0.5151953181675657. Breakdown:\n",
      "\tEvaluation mean reward = 0.53, normalized = -0.9999893474929373, weighted = -0.6999925432450561\n",
      "\tTraining mean reward = 0.72, normalized = 0.6133572603953845, weighted = 0.061335726039538456\n",
      "\tTraining episodes = 2001, normalized = 0.6173074951897601, weighted = 0.12346149903795203\n",
      "Total score across all environments for seed 90 = -0.5151953181675657\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 90 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=1.0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.996, value=1.0)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.073, decay_rate=0.964, value=1.0)}\n",
      "Score in the FrozenLakeEnv environment with seed 56:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.993386272680481, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.999, value=0.993)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.09, decay_rate=0.996, value=0.09))\n",
      "Score = 0.9797673554794631. Breakdown:\n",
      "\tEvaluation mean reward = 0.77, normalized = 0.9866142981514305, weighted = 0.6906300087060013\n",
      "\tTraining mean reward = 0.74, normalized = 0.8913734677347187, weighted = 0.08913734677347188\n",
      "\tTraining episodes = 751, normalized = 0.9999999999999498, weighted = 0.19999999999998996\n",
      "Total score across all environments for seed 56 = 0.9797673554794631\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 12 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.11536442599539684, ConstantSchedule(value=0.115)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=1.0)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4d7670f1ef44d8cb9581ed861302fc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8215783cd228482d84f8bb4e09142ff8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score in the FrozenLakeEnv environment with seed 78:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9991580718127149, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=0.999)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=0.074))\n",
      "Score = 0.32176635945606485. Breakdown:\n",
      "\tEvaluation mean reward = 0.71, normalized = 0.3426949069654588, weighted = 0.23988643487582115\n",
      "\tTraining mean reward = 0.76, normalized = 0.9728461661125116, weighted = 0.09728461661125117\n",
      "\tTraining episodes = 2501, normalized = -0.07702346015503725, weighted = -0.015404692031007451\n",
      "Total score across all environments for seed 78 = 0.32176635945606485\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 34 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.11536442599539684, ConstantSchedule(value=0.115)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=1.0)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4720cff17c8d4645b34187dae18b17e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score in the FrozenLakeEnv environment with seed 90:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.7760286357937183, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.98, value=0.776)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=0.074))\n",
      "Score = 0.5162723307387312. Breakdown:\n",
      "\tEvaluation mean reward = 0.73, normalized = 0.7899988299594711, weighted = 0.5529991809716297\n",
      "\tTraining mean reward = 0.74, normalized = 0.8913734677347187, weighted = 0.08913734677347188\n",
      "\tTraining episodes = 3101, normalized = -0.6293209850318515, weighted = -0.1258641970063703\n",
      "Total score across all environments for seed 90 = 0.5162723307387312\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 56 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.11536442599539684, ConstantSchedule(value=0.115)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=1.0)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bd3dd6279fb4bf0938a7e1f7b3d0a09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score in the FrozenLakeEnv environment with seed 56:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9752226010222359, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.996, value=0.975)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=0.074))\n",
      "Score = -0.46171459218150857. Breakdown:\n",
      "\tEvaluation mean reward = 0.65, normalized = -0.9453064264076338, weighted = -0.6617144984853437\n",
      "\tTraining mean reward = 0.7, normalized = 0.0, weighted = 0.0\n",
      "\tTraining episodes = 1001, normalized = 0.9999995315191756, weighted = 0.19999990630383513\n",
      "Total score across all environments for seed 56 = -0.46171459218150857\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 78 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.11536442599539684, ConstantSchedule(value=0.115)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=1.0)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bac6a57818004b7c96c38fac62fe0965",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 34:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9943284060533764, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.999, value=0.994)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.09, decay_rate=0.996, value=0.09))\n",
      "Score = 0.8818201526316455. Breakdown:\n",
      "\tEvaluation mean reward = 0.74, normalized = 0.8913734677347187, weighted = 0.623961427414303\n",
      "\tTraining mean reward = 0.72, normalized = 0.6133572603953845, weighted = 0.061335726039538456\n",
      "\tTraining episodes = 1501, normalized = 0.98261499588902, weighted = 0.19652299917780403\n",
      "Total score across all environments for seed 34 = 0.8818201526316455\n",
      "---------------------------------------------\n",
      "\n",
      "Training on FrozenLakeEnv environment with seed 90 and params {'behavioral_strategy': EpsilonGreedyPolicy(epsilon=0.11536442599539684, ConstantSchedule(value=0.115)), 'alpha': ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=1.0)}\n",
      "Score in the FrozenLakeEnv environment with seed 34:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.8778338013420282, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.98, value=0.878)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=0.074))\n",
      "Score = -0.7712874297625112. Breakdown:\n",
      "\tEvaluation mean reward = 0.66, normalized = -0.8913734677347183, weighted = -0.6239614274143027\n",
      "\tTraining mean reward = 0.7, normalized = 0.0, weighted = 0.0\n",
      "\tTraining episodes = 3301, normalized = -0.736630011741042, weighted = -0.14732600234820842\n",
      "Total score across all environments for seed 34 = -0.7712874297625112\n",
      "---------------------------------------------\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeab908d016043dfa1b5e3beec1c6d00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score in the FrozenLakeEnv environment with seed 56:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9752226010222359, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.996, value=0.975)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.073, decay_rate=0.964, value=0.073))\n",
      "Score = -0.46171459218150857. Breakdown:\n",
      "\tEvaluation mean reward = 0.65, normalized = -0.9453064264076338, weighted = -0.6617144984853437\n",
      "\tTraining mean reward = 0.7, normalized = 0.0, weighted = 0.0\n",
      "\tTraining episodes = 1001, normalized = 0.9999995315191756, weighted = 0.19999990630383513\n",
      "Total score across all environments for seed 56 = -0.46171459218150857\n",
      "---------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 12:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.972295936209412, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=0.972)), alpha=ConstantSchedule(value=0.723))\n",
      "Score = -0.9999999999999908. Breakdown:\n",
      "\tEvaluation mean reward = 0.05, normalized = -1.0, weighted = -0.7\n",
      "\tTraining mean reward = 0.27, normalized = -0.9999999999999084, weighted = -0.09999999999999085\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 12 = -0.9999999999999908\n",
      "---------------------------------------------\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 56:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9990377963573884, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=0.999)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.09, decay_rate=0.996, value=0.09))\n",
      "Score = 0.607274321211307. Breakdown:\n",
      "\tEvaluation mean reward = 0.79, normalized = 0.9967756945029476, weighted = 0.6977429861520632\n",
      "\tTraining mean reward = 0.72, normalized = 0.6133572603953845, weighted = 0.061335726039538456\n",
      "\tTraining episodes = 3351, normalized = -0.759021954901473, weighted = -0.1518043909802946\n",
      "Total score across all environments for seed 56 = 0.607274321211307\n",
      "---------------------------------------------\n",
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 56:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9873107148941298, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.001, decay_rate=0.997, value=0.987)), alpha=ConstantSchedule(value=0.723))\n",
      "Score = -0.9999999999999999. Breakdown:\n",
      "\tEvaluation mean reward = 0.01, normalized = -1.0, weighted = -0.7\n",
      "\tTraining mean reward = 0.0, normalized = -1.0, weighted = -0.1\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 56 = -0.9999999999999999\n",
      "---------------------------------------------\n",
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 12:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9752226010222359, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.996, value=0.975)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.073, decay_rate=0.964, value=0.073))\n",
      "Score = -0.1481848838349697. Breakdown:\n",
      "\tEvaluation mean reward = 0.68, normalized = -0.613357260395381, weighted = -0.42935008227676663\n",
      "\tTraining mean reward = 0.78, normalized = 0.9934246772281319, weighted = 0.09934246772281319\n",
      "\tTraining episodes = 1701, normalized = 0.9091136535949187, weighted = 0.18182273071898375\n",
      "Total score across all environments for seed 12 = -0.1481848838349697\n",
      "---------------------------------------------\n",
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 78:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)), alpha=ConstantSchedule(value=0.341))\n",
      "Score = -0.5464303826041197. Breakdown:\n",
      "\tEvaluation mean reward = 0.67, normalized = -0.7899988299594689, weighted = -0.5529991809716281\n",
      "\tTraining mean reward = 0.71, normalized = 0.3426949069654588, weighted = 0.03426949069654588\n",
      "\tTraining episodes = 2551, normalized = -0.13850346164518668, weighted = -0.027700692329037338\n",
      "Total score across all environments for seed 78 = -0.5464303826041197\n",
      "---------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 90:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9943284060533764, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.999, value=0.994)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.09, decay_rate=0.996, value=0.09))\n",
      "Score = -0.4713485465475253. Breakdown:\n",
      "\tEvaluation mean reward = 0.55, normalized = -0.9999555506739739, weighted = -0.6999688854717817\n",
      "\tTraining mean reward = 0.72, normalized = 0.6133572603953845, weighted = 0.061335726039538456\n",
      "\tTraining episodes = 1801, normalized = 0.8364230644235897, weighted = 0.16728461288471796\n",
      "Total score across all environments for seed 90 = -0.4713485465475253\n",
      "---------------------------------------------\n",
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 78:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9981058832714378, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.999, value=0.998)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.09, decay_rate=0.996, value=0.09))\n",
      "Score = -0.5523573530877045. Breakdown:\n",
      "\tEvaluation mean reward = 0.56, normalized = -0.9999092042625951, weighted = -0.6999364429838165\n",
      "\tTraining mean reward = 0.7, normalized = 0.0, weighted = 0.0\n",
      "\tTraining episodes = 1901, normalized = 0.7378954494805599, weighted = 0.147579089896112\n",
      "Total score across all environments for seed 78 = -0.5523573530877045\n",
      "---------------------------------------------\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 78:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.8948396355581706, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.996, value=0.895)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.073, decay_rate=0.964, value=0.073))\n",
      "Score = 0.8471861086764909. Breakdown:\n",
      "\tEvaluation mean reward = 0.73, normalized = 0.7899988299594711, weighted = 0.5529991809716297\n",
      "\tTraining mean reward = 0.8, normalized = 0.9984202681165271, weighted = 0.09984202681165272\n",
      "\tTraining episodes = 1551, normalized = 0.9717245044660427, weighted = 0.19434490089320855\n",
      "Total score across all environments for seed 78 = 0.8471861086764909\n",
      "---------------------------------------------\n",
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 12:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9476564200714348, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.996, value=0.948)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=0.074))\n",
      "Score = -0.20654611551600144. Breakdown:\n",
      "\tEvaluation mean reward = 0.68, normalized = -0.613357260395381, weighted = -0.42935008227676663\n",
      "\tTraining mean reward = 0.78, normalized = 0.9934246772281319, weighted = 0.09934246772281319\n",
      "\tTraining episodes = 2001, normalized = 0.6173074951897601, weighted = 0.12346149903795203\n",
      "Total score across all environments for seed 12 = -0.20654611551600144\n",
      "---------------------------------------------\n",
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 34:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9175747512621146, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.996, value=0.918)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=0.074))\n",
      "Score = -0.6221423414349387. Breakdown:\n",
      "\tEvaluation mean reward = 0.65, normalized = -0.9453064264076338, weighted = -0.6617144984853437\n",
      "\tTraining mean reward = 0.73, normalized = 0.7899988299594711, weighted = 0.07899988299594712\n",
      "\tTraining episodes = 2601, normalized = -0.19713862972771112, weighted = -0.039427725945542225\n",
      "Total score across all environments for seed 34 = -0.6221423414349387\n",
      "---------------------------------------------\n",
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 78:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9822385382330083, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.996, value=0.982)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=0.074))\n",
      "Score = -0.7276371353128539. Breakdown:\n",
      "\tEvaluation mean reward = 0.56, normalized = -0.9999092042625951, weighted = -0.6999364429838165\n",
      "\tTraining mean reward = 0.7, normalized = 0.0, weighted = 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTraining episodes = 2551, normalized = -0.13850346164518668, weighted = -0.027700692329037338\n",
      "Total score across all environments for seed 78 = -0.7276371353128539\n",
      "---------------------------------------------\n",
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 34:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9175747512621146, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.996, value=0.918)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.073, decay_rate=0.964, value=0.073))\n",
      "Score = -0.6221423414349387. Breakdown:\n",
      "\tEvaluation mean reward = 0.65, normalized = -0.9453064264076338, weighted = -0.6617144984853437\n",
      "\tTraining mean reward = 0.73, normalized = 0.7899988299594711, weighted = 0.07899988299594712\n",
      "\tTraining episodes = 2601, normalized = -0.19713862972771112, weighted = -0.039427725945542225\n",
      "Total score across all environments for seed 34 = -0.6221423414349387\n",
      "---------------------------------------------\n",
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 78:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=0.052))\n",
      "Score = -0.3275633181588307. Breakdown:\n",
      "\tEvaluation mean reward = 0.69, normalized = -0.34269490696546123, weighted = -0.23988643487582284\n",
      "\tTraining mean reward = 0.75, normalized = 0.9453064264076343, weighted = 0.09453064264076344\n",
      "\tTraining episodes = 3851, normalized = -0.9110376296188566, weighted = -0.18220752592377132\n",
      "Total score across all environments for seed 78 = -0.3275633181588307\n",
      "---------------------------------------------\n",
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 12:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)), alpha=ConstantSchedule(value=0.341))\n",
      "Score = -0.9999999999999999. Breakdown:\n",
      "\tEvaluation mean reward = 0.0, normalized = -1.0, weighted = -0.7\n",
      "\tTraining mean reward = 0.0, normalized = -1.0, weighted = -0.1\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 12 = -0.9999999999999999\n",
      "---------------------------------------------\n",
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 90:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9857654119503506, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.996, value=0.986)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=0.074))\n",
      "Score = -0.2702482508612507. Breakdown:\n",
      "\tEvaluation mean reward = 0.69, normalized = -0.34269490696546123, weighted = -0.23988643487582284\n",
      "\tTraining mean reward = 0.74, normalized = 0.8913734677347187, weighted = 0.08913734677347188\n",
      "\tTraining episodes = 3051, normalized = -0.5974958137944986, weighted = -0.11949916275889971\n",
      "Total score across all environments for seed 90 = -0.2702482508612507\n",
      "---------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 34:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=0.052))\n",
      "Score = -0.9999999999999999. Breakdown:\n",
      "\tEvaluation mean reward = 0.0, normalized = -1.0, weighted = -0.7\n",
      "\tTraining mean reward = 0.0, normalized = -1.0, weighted = -0.1\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 34 = -0.9999999999999999\n",
      "---------------------------------------------\n",
      "Score in the FrozenLakeEnv environment with seed 34:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)), alpha=ConstantSchedule(value=0.341))\n",
      "Score = -0.9999999999999999. Breakdown:\n",
      "\tEvaluation mean reward = 0.0, normalized = -1.0, weighted = -0.7\n",
      "\tTraining mean reward = 0.0, normalized = -1.0, weighted = -0.1\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "\n",
      "Total score across all environments for seed 34 = -0.9999999999999999\n",
      "---------------------------------------------\n",
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 90:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)), alpha=ConstantSchedule(value=0.341))\n",
      "Score = -0.9999999999999999. Breakdown:\n",
      "\tEvaluation mean reward = 0.0, normalized = -1.0, weighted = -0.7\n",
      "\tTraining mean reward = 0.0, normalized = -1.0, weighted = -0.1\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 90 = -0.9999999999999999\n",
      "---------------------------------------------\n",
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 12:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=0.052))\n",
      "Score = -0.9999999999999999. Breakdown:\n",
      "\tEvaluation mean reward = 0.0, normalized = -1.0, weighted = -0.7\n",
      "\tTraining mean reward = 0.0, normalized = -1.0, weighted = -0.1\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 12 = -0.9999999999999999\n",
      "---------------------------------------------\n",
      "\n",
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 56:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)), alpha=ConstantSchedule(value=0.341))\n",
      "Score = -0.9999999999999999. Breakdown:\n",
      "\tEvaluation mean reward = 0.0, normalized = -1.0, weighted = -0.7\n",
      "\tTraining mean reward = 0.0, normalized = -1.0, weighted = -0.1\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 56 = -0.9999999999999999\n",
      "---------------------------------------------\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 90:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=0.052))\n",
      "Score = -0.9999999999999999. Breakdown:\n",
      "\tEvaluation mean reward = 0.0, normalized = -1.0, weighted = -0.7\n",
      "\tTraining mean reward = 0.0, normalized = -1.0, weighted = -0.1\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 90 = -0.9999999999999999\n",
      "---------------------------------------------\n",
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 56:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.0775019291289278, ConstantSchedule(value=0.078)), alpha=LinearlyDecayingSchedule(initial_value=1.0, min_value=0.052, decay_rate=0.976, value=0.052))\n",
      "Score = -0.9999999999999999. Breakdown:\n",
      "\tEvaluation mean reward = 0.0, normalized = -1.0, weighted = -0.7\n",
      "\tTraining mean reward = 0.0, normalized = -1.0, weighted = -0.1\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 56 = -0.9999999999999999\n",
      "---------------------------------------------\n",
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 12:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9990524927507252, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.999, value=0.999)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.09, decay_rate=0.996, value=0.09))\n",
      "Score = 0.15082164403942397. Breakdown:\n",
      "\tEvaluation mean reward = 0.71, normalized = 0.3426949069654588, weighted = 0.23988643487582115\n",
      "\tTraining mean reward = 0.82, normalized = 0.9996211881123498, weighted = 0.09996211881123498\n",
      "\tTraining episodes = 4051, normalized = -0.9451345482381608, weighted = -0.18902690964763216\n",
      "Total score across all environments for seed 12 = 0.15082164403942397\n",
      "---------------------------------------------\n",
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 90:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9991580718127149, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.012, decay_rate=1.0, value=0.999)), alpha=ConstantSchedule(value=0.603))\n",
      "Score = -0.9999999999999999. Breakdown:\n",
      "\tEvaluation mean reward = 0.08, normalized = -1.0, weighted = -0.7\n",
      "\tTraining mean reward = 0.08, normalized = -1.0, weighted = -0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 90 = -0.9999999999999999\n",
      "---------------------------------------------\n",
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 90:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.9613407090399768, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.996, value=0.961)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.073, decay_rate=0.964, value=0.073))\n",
      "Score = 0.4627485378883773. Breakdown:\n",
      "\tEvaluation mean reward = 0.73, normalized = 0.7899988299594711, weighted = 0.5529991809716297\n",
      "\tTraining mean reward = 0.76, normalized = 0.9728461661125116, weighted = 0.09728461661125117\n",
      "\tTraining episodes = 4001, normalized = -0.9376762984725178, weighted = -0.18753525969450358\n",
      "Total score across all environments for seed 90 = 0.4627485378883773\n",
      "---------------------------------------------\n",
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 34:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.11536442599539684, ConstantSchedule(value=0.115)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=0.074))\n",
      "Score = -0.9999999999999999. Breakdown:\n",
      "\tEvaluation mean reward = 0.0, normalized = -1.0, weighted = -0.7\n",
      "\tTraining mean reward = 0.0, normalized = -1.0, weighted = -0.1\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 34 = -0.9999999999999999\n",
      "---------------------------------------------\n",
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 12:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.11536442599539684, ConstantSchedule(value=0.115)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=0.074))\n",
      "Score = -0.9999999999999999. Breakdown:\n",
      "\tEvaluation mean reward = 0.0, normalized = -1.0, weighted = -0.7\n",
      "\tTraining mean reward = 0.0, normalized = -1.0, weighted = -0.1\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 12 = -0.9999999999999999\n",
      "---------------------------------------------\n",
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 78:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.11536442599539684, ConstantSchedule(value=0.115)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=0.074))\n",
      "Score = -0.9999999999999999. Breakdown:\n",
      "\tEvaluation mean reward = 0.0, normalized = -1.0, weighted = -0.7\n",
      "\tTraining mean reward = 0.0, normalized = -1.0, weighted = -0.1\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 78 = -0.9999999999999999\n",
      "---------------------------------------------\n",
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 90:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.11536442599539684, ConstantSchedule(value=0.115)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=0.074))\n",
      "Score = -0.9999999999999999. Breakdown:\n",
      "\tEvaluation mean reward = 0.0, normalized = -1.0, weighted = -0.7\n",
      "\tTraining mean reward = 0.0, normalized = -1.0, weighted = -0.1\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 90 = -0.9999999999999999\n",
      "---------------------------------------------\n",
      "\n",
      "\n",
      "Score in the FrozenLakeEnv environment with seed 56:\n",
      "Agent = Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=0.11536442599539684, ConstantSchedule(value=0.115)), alpha=ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.074, decay_rate=0.991, value=0.074))\n",
      "Score = 0.40492779780833704. Breakdown:\n",
      "\tEvaluation mean reward = 0.81, normalized = 0.999226343498715, weighted = 0.6994584404491004\n",
      "\tTraining mean reward = 0.65, normalized = -0.9453064264076338, weighted = -0.09453064264076338\n",
      "\tTraining episodes = 5000, normalized = -1.0, weighted = -0.2\n",
      "Total score across all environments for seed 56 = 0.40492779780833704\n",
      "---------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=<__main__.OneToOneCV object at 0x7f904f7fccf8>,\n",
       "          error_score='raise', estimator=Qlearning(), fit_params=None,\n",
       "          iid=False, n_iter=30, n_jobs=-1,\n",
       "          param_distributions={'alpha': [ConstantSchedule(value=0.603), ConstantSchedule(value=0.723), ConstantSchedule(value=0.744), ConstantSchedule(value=0.341), ConstantSchedule(value=0.393), LinearlyDecayingSchedule(initial_value=1.0, min_value=0.098, decay_rate=1.0, value=1.0), LinearlyDecayingSchedule(...0, ExponentiallyDecayingSchedule(initial_value=1.0, min_value=0.005, decay_rate=0.999, value=1.0))]},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=False,\n",
       "          return_train_score=False, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent = Qlearning()\n",
    "rsearch = RandomizedSearchCV(estimator=agent, \n",
    "                             param_distributions=grid.data(), \n",
    "                             n_iter=len(grid),\n",
    "                             cv=OneToOneCV(), \n",
    "                             refit=False,\n",
    "                             iid=False,\n",
    "                             return_train_score=False,\n",
    "                             n_jobs=-1,\n",
    "                             verbose=0)\n",
    "rsearch.fit(training_configuration.data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score 0.7931762333491787\n",
      "alpha ConstantSchedule(value=0.723)\n",
      "behavioral_strategy EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.009, decay_rate=0.988, value=1.0))\n"
     ]
    }
   ],
   "source": [
    "print('best score', rsearch.best_score_)\n",
    "print('alpha', rsearch.best_params_['alpha'])\n",
    "print('behavioral_strategy', rsearch.best_params_['behavioral_strategy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qlearning(behavioral_strategy=EpsilonGreedyPolicy(epsilon=1.0, LinearlyDecayingSchedule(initial_value=1.0, min_value=0.009, decay_rate=0.988, value=1.0)), alpha=ConstantSchedule(value=0.723))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.set_params(**rsearch.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f33423f78114a2e889a941032c78fc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'FrozenLakeEnv': {'Q': array([[8.83171143e-01, 8.48361547e-01, 8.63116620e-01, 8.34891007e-01],\n",
       "         [2.19993193e-01, 8.30016277e-01, 8.43245574e-01, 8.32565747e-01],\n",
       "         [8.72758359e-01, 8.64602813e-01, 8.17897299e-01, 8.60120241e-01],\n",
       "         [8.15647246e-01, 6.04349267e-01, 2.17381815e-01, 8.17316040e-01],\n",
       "         [8.81167715e-01, 1.98094579e-01, 2.48495198e-01, 6.77279527e-01],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [8.72912085e-01, 8.34838009e-01, 6.94591618e-02, 3.46298619e-04],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [8.96017829e-01, 2.54315351e-01, 8.30648582e-01, 9.12210522e-01],\n",
       "         [8.65292166e-01, 9.51337417e-01, 7.51824650e-01, 8.48523853e-01],\n",
       "         [9.49771466e-01, 2.56589306e-01, 8.21890496e-01, 2.21240698e-01],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "         [8.55617926e-01, 9.65224347e-01, 9.77256629e-01, 2.46943751e-01],\n",
       "         [9.32548702e-01, 9.78161953e-01, 9.45735787e-01, 9.65264187e-01],\n",
       "         [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00]]),\n",
       "  'V': array([0.88317114, 0.84324557, 0.87275836, 0.81731604, 0.88116771,\n",
       "         0.        , 0.87291208, 0.        , 0.91221052, 0.95133742,\n",
       "         0.94977147, 0.        , 0.        , 0.97725663, 0.97816195,\n",
       "         0.        ]),\n",
       "  'policy': {0: 0,\n",
       "   1: 2,\n",
       "   2: 0,\n",
       "   3: 3,\n",
       "   4: 0,\n",
       "   5: 0,\n",
       "   6: 0,\n",
       "   7: 0,\n",
       "   8: 3,\n",
       "   9: 1,\n",
       "   10: 0,\n",
       "   11: 0,\n",
       "   12: 0,\n",
       "   13: 2,\n",
       "   14: 1,\n",
       "   15: 0},\n",
       "  'training_episodes': 1551,\n",
       "  'training_mean_reward': 0.73}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = {}\n",
    "for environment in environments:\n",
    "    results[environment.get_environment_name()] = agent.train(environment.env, \n",
    "                                                              environment.gamma,\n",
    "                                                              environment.max_episodes, \n",
    "                                                              environment.goal_mean_reward)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "  (Up)\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "  (Up)\n",
      "SFFF\n",
      "FHFH\n",
      "F\u001b[41mF\u001b[0mFH\n",
      "HFFG\n",
      "  (Down)\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "  (Up)\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "  (Up)\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "  (Up)\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "  (Up)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "  (Up)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "  (Up)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "  (Up)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "  (Up)\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "  (Up)\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "  (Up)\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "  (Up)\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "  (Up)\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "  (Up)\n",
      "SFFF\n",
      "FHFH\n",
      "F\u001b[41mF\u001b[0mFH\n",
      "HFFG\n",
      "  (Down)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "H\u001b[41mF\u001b[0mFG\n",
      "  (Right)\n",
      "SFFF\n",
      "FHFH\n",
      "F\u001b[41mF\u001b[0mFH\n",
      "HFFG\n",
      "  (Down)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "H\u001b[41mF\u001b[0mFG\n",
      "  (Right)\n",
      "SFFF\n",
      "FHFH\n",
      "F\u001b[41mF\u001b[0mFH\n",
      "HFFG\n",
      "  (Down)\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "  (Up)\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "  (Up)\n",
      "SFFF\n",
      "FHFH\n",
      "F\u001b[41mF\u001b[0mFH\n",
      "HFFG\n",
      "  (Down)\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "  (Up)\n",
      "SFFF\n",
      "FHFH\n",
      "F\u001b[41mF\u001b[0mFH\n",
      "HFFG\n",
      "  (Down)\n",
      "SFFF\n",
      "FHFH\n",
      "FF\u001b[41mF\u001b[0mH\n",
      "HFFG\n",
      "  (Left)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HF\u001b[41mF\u001b[0mG\n",
      "  (Down)\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFF\u001b[41mG\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "for environment in environments:\n",
    "    agent.demo(environment, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
